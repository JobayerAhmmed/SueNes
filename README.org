#+TITLE: Anti Rouge

* TodoList
** Experiment
*** TODO use all CNN data
*** TODO use DM data
*** TODO [#B] use the model learned from CNN data to test on DM data (transfer)
*** TODO [#A] use fake summary and difference as loss function, instead of mutation and score
*** DONE [#A] use only mutated summary, without article
    CLOSED: [2018-11-30 Fri 15:07]
*** TODO when generating mutation, do not change sentence separator
*** TODO adjust hyper parameters and network architecture
*** TODO try LSTM and attention, MLP instead of current CNN

** New Experiment

All with 4 settings:
- UAE
- UAE-Large
- Glove
- Glove-SO
*** TODO FIXME word mutate avoid sepator
*** TODO [#A] sigmoid on regression problem
*** TODO [#A] classification, use hinge loss
*** TODO LSTM model train more epochs
*** TODO sentence-level mutate

*** TODO mutation with deletion only
good
*** TODO negative sampling with CNN/DM
N/A

*** TODO negative sampling with NYT
*** TODO sentence level mutation with NYT

*** TODO 2nd negative sampling
For reference summary, shuffle the order of words, so that the
sentence don't make sense. Expect the word embedding (glove) based
model to have no impact, but sentence embedding method should observe
a major drop, since the sentence does not make sense.

*** DONE softmax instead of sigmoid
    CLOSED: [2018-12-05 Wed 12:41]
*** TODO negative sampling difference loss function
*** TODO validation and test dataset
*** TODO regularizers (L1, L2, dropout)
*** DONE USE-Large
    CLOSED: [2018-12-04 Tue 21:03]
*** DONE CNN architecture change
    CLOSED: [2018-12-04 Tue 21:58]
- smaller number of CNN
- dropout
- conv2d
*** TODO separate architecture

*** TODO NOW automatic early stop keras

** Paper writing
*** TODO write method
*** TODO figures
*** TODO plot results

* Code structure and usage instruction

- =model.py=: models
- =embedding.py=: load glove embedding and USE sentence embedding
- =data.py=: prepare data
- =preprocessing.py=
- =config.py=: hyper parameters

=main.py= glue the data and model together: load data, build model,
train and validate results. Various of experiments are defined in the
following functions.
- =glove_main=
- =use_vector_main=
- =glove_summary_main=

See [[file:log.org][log.org]] for the experiment log.

* Mutation operator

    MODE can be add, delete, mutate (TODO). Generate 10 for each mode.
    
    I need to generate random mutation to the summary. Save it to a
    file so that I use the same generated data. For each summary, I
    generate several data:
        
    1. generate 10 random float numbers [0,1] as ratios
    2. for each ratio, do:
    2.1 deletion: select ratio percent of words to remove
    2.2 addition: add ratio percent of new words (from vocab.txt) to
    random places

    Issues:
    
    - should I add better, regularized noise, e.g. gaussian noise? How
      to do that?
    - should I check if the sentence is really modified?
    - should we use the text from original article?
    - should we treat sentences? should we maintain the sentence
      separator period?
