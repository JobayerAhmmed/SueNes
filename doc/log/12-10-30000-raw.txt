~/github/anti-rouge $ bash runner.sh
EXP 1
Mon Dec 10 02:44:36 CST 2018
python3 main.py neg glove FC
Using TensorFlow backend.
Setting:  neg glove 30000 1 FC None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14470100  
_________________________________________________________________
flatten_1 (Flatten)          (None, 114600)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               14668928  
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 29,139,157
Trainable params: 14,669,057
Non-trainable params: 14,470,100
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 02:45:24.179526: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 02:45:24.299338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 02:45:24.300022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 02:45:24.300041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 02:45:25.247743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 02:45:25.247779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 02:45:25.247786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 02:45:25.248730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 6s 134us/step - loss: 0.7085 - acc: 0.4962 - pearson_correlation_f: nan - val_loss: 0.6917 - val_acc: 0.4998 - val_pearson_correlation_f: nan
Epoch 2/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.6932 - acc: 0.5197 - pearson_correlation_f: 0.1155 - val_loss: 0.6922 - val_acc: 0.5380 - val_pearson_correlation_f: 0.1526
Epoch 3/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.6740 - acc: 0.5424 - pearson_correlation_f: 0.2003 - val_loss: 0.6654 - val_acc: 0.5567 - val_pearson_correlation_f: 0.2219
Epoch 4/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.6536 - acc: 0.5673 - pearson_correlation_f: 0.2724 - val_loss: 0.6565 - val_acc: 0.5675 - val_pearson_correlation_f: 0.2524
Epoch 5/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.6300 - acc: 0.5872 - pearson_correlation_f: 0.3237 - val_loss: 0.6466 - val_acc: 0.5858 - val_pearson_correlation_f: 0.2922
Epoch 6/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.6107 - acc: 0.6027 - pearson_correlation_f: 0.3641 - val_loss: 0.6622 - val_acc: 0.5730 - val_pearson_correlation_f: 0.2672
Epoch 7/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.5969 - acc: 0.6125 - pearson_correlation_f: 0.3909 - val_loss: 0.6542 - val_acc: 0.5867 - val_pearson_correlation_f: 0.2889
Epoch 8/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.5867 - acc: 0.6218 - pearson_correlation_f: 0.4078 - val_loss: 0.6933 - val_acc: 0.6128 - val_pearson_correlation_f: 0.3105
6000/6000 [==============================] - 0s 70us/step
Test result:  [0.6697701627413432, 0.6196666666666667, 0.31974834216634435]
python3 main.py neg glove CNN
Using TensorFlow backend.
Setting:  neg glove 30000 1 CNN None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14414000  
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1142, 128)         64128     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 380, 128)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,494,769
Trainable params: 80,769
Non-trainable params: 14,414,000
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 02:46:48.561263: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 02:46:48.656186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 02:46:48.656675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 02:46:48.656691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 02:46:48.829726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 02:46:48.829760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 02:46:48.829766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 02:46:48.829908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 14s 295us/step - loss: 0.7055 - acc: 0.5183 - pearson_correlation_f: 0.0903 - val_loss: 0.6608 - val_acc: 0.6045 - val_pearson_correlation_f: 0.2924
Epoch 2/60
48000/48000 [==============================] - 12s 257us/step - loss: 0.6462 - acc: 0.6208 - pearson_correlation_f: 0.3410 - val_loss: 0.6117 - val_acc: 0.6653 - val_pearson_correlation_f: 0.4080
Epoch 3/60
48000/48000 [==============================] - 12s 257us/step - loss: 0.6042 - acc: 0.6694 - pearson_correlation_f: 0.4416 - val_loss: 0.6170 - val_acc: 0.6517 - val_pearson_correlation_f: 0.4560
Epoch 4/60
48000/48000 [==============================] - 12s 258us/step - loss: 0.5689 - acc: 0.6995 - pearson_correlation_f: 0.5075 - val_loss: 0.5805 - val_acc: 0.6922 - val_pearson_correlation_f: 0.4979
Epoch 5/60
48000/48000 [==============================] - 12s 260us/step - loss: 0.5381 - acc: 0.7219 - pearson_correlation_f: 0.5553 - val_loss: 0.5434 - val_acc: 0.7203 - val_pearson_correlation_f: 0.5196
Epoch 6/60
48000/48000 [==============================] - 13s 266us/step - loss: 0.5132 - acc: 0.7408 - pearson_correlation_f: 0.5951 - val_loss: 0.5451 - val_acc: 0.7200 - val_pearson_correlation_f: 0.5299
Epoch 7/60
48000/48000 [==============================] - 13s 268us/step - loss: 0.4875 - acc: 0.7582 - pearson_correlation_f: 0.6282 - val_loss: 0.5500 - val_acc: 0.7248 - val_pearson_correlation_f: 0.5366
Epoch 8/60
48000/48000 [==============================] - 13s 268us/step - loss: 0.4632 - acc: 0.7740 - pearson_correlation_f: 0.6570 - val_loss: 0.5390 - val_acc: 0.7327 - val_pearson_correlation_f: 0.5411
Epoch 9/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.4409 - acc: 0.7884 - pearson_correlation_f: 0.6830 - val_loss: 0.5993 - val_acc: 0.7040 - val_pearson_correlation_f: 0.5300
Epoch 10/60
48000/48000 [==============================] - 13s 271us/step - loss: 0.4222 - acc: 0.7980 - pearson_correlation_f: 0.7054 - val_loss: 0.6695 - val_acc: 0.7063 - val_pearson_correlation_f: 0.5313
Epoch 11/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.4023 - acc: 0.8079 - pearson_correlation_f: 0.7255 - val_loss: 0.5659 - val_acc: 0.7353 - val_pearson_correlation_f: 0.5418
6000/6000 [==============================] - 1s 126us/step
Test result:  [0.567976142168045, 0.7305, 0.5494631524085999]
python3 main.py neg glove LSTM
Using TensorFlow backend.
Setting:  neg glove 30000 1 LSTM None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14554800  
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               117248    
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,672,177
Trainable params: 117,377
Non-trainable params: 14,554,800
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 02:49:58.537958: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 02:49:58.631440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 02:49:58.631882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 02:49:58.631899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 02:49:58.806017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 02:49:58.806055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 02:49:58.806061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 02:49:58.806215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 441s 9ms/step - loss: 0.6946 - acc: 0.4977 - pearson_correlation_f: -0.0035 - val_loss: 0.6936 - val_acc: 0.4972 - val_pearson_correlation_f: 0.0019
Epoch 2/60
48000/48000 [==============================] - 439s 9ms/step - loss: 0.6933 - acc: 0.5053 - pearson_correlation_f: 0.0211 - val_loss: 0.6939 - val_acc: 0.4980 - val_pearson_correlation_f: -0.0057
Epoch 3/60
48000/48000 [==============================] - 438s 9ms/step - loss: 0.6923 - acc: 0.5091 - pearson_correlation_f: 0.0439 - val_loss: 0.6951 - val_acc: 0.4895 - val_pearson_correlation_f: -0.0285
Epoch 4/60
48000/48000 [==============================] - 439s 9ms/step - loss: 0.6912 - acc: 0.5195 - pearson_correlation_f: 0.0644 - val_loss: 0.6962 - val_acc: 0.4917 - val_pearson_correlation_f: -0.0274
6000/6000 [==============================] - 65s 11ms/step
Test result:  [0.6954789371490478, 0.4895, -0.021259055877725284]
python3 main.py neg USE FC
Using TensorFlow backend.
Setting:  neg USE 30000 1 FC None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:21:34.412854: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:21:34.984767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:21:34.985361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:21:34.985384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:21:45.016701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:21:45.016744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:21:45.016759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:21:45.019079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 18s 385us/step - loss: 0.6756 - acc: 0.5514 - pearson_correlation_f: 0.1613 - val_loss: 0.6200 - val_acc: 0.6348 - val_pearson_correlation_f: 0.4112
Epoch 2/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.5686 - acc: 0.7013 - pearson_correlation_f: 0.4942 - val_loss: 0.4912 - val_acc: 0.7808 - val_pearson_correlation_f: 0.6115
Epoch 3/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.4520 - acc: 0.7935 - pearson_correlation_f: 0.6607 - val_loss: 0.4310 - val_acc: 0.8132 - val_pearson_correlation_f: 0.6727
Epoch 4/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.3658 - acc: 0.8443 - pearson_correlation_f: 0.7508 - val_loss: 0.4244 - val_acc: 0.8163 - val_pearson_correlation_f: 0.6917
Epoch 5/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.2943 - acc: 0.8831 - pearson_correlation_f: 0.8156 - val_loss: 0.3954 - val_acc: 0.8332 - val_pearson_correlation_f: 0.7173
Epoch 6/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.2360 - acc: 0.9099 - pearson_correlation_f: 0.8616 - val_loss: 0.3878 - val_acc: 0.8407 - val_pearson_correlation_f: 0.7295
Epoch 7/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.1836 - acc: 0.9336 - pearson_correlation_f: 0.8978 - val_loss: 0.4410 - val_acc: 0.8260 - val_pearson_correlation_f: 0.7166
Epoch 8/60
48000/48000 [==============================] - 3s 72us/step - loss: 0.1453 - acc: 0.9495 - pearson_correlation_f: 0.9219 - val_loss: 0.4229 - val_acc: 0.8397 - val_pearson_correlation_f: 0.7262
Epoch 9/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.1163 - acc: 0.9621 - pearson_correlation_f: 0.9397 - val_loss: 0.4657 - val_acc: 0.8357 - val_pearson_correlation_f: 0.7247
6000/6000 [==============================] - 0s 65us/step
Test result:  [0.4792586327791214, 0.8321666666666667, 0.7215337328116099]
python3 main.py neg USE CNN
Using TensorFlow backend.
Setting:  neg USE 30000 1 CNN None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:23:59.365482: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:23:59.951952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:23:59.952465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:23:59.952484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:24:10.864330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:24:10.864370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:24:10.864379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:24:10.867459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 03:24:16.181927: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
48000/48000 [==============================] - 21s 441us/step - loss: 0.6707 - acc: 0.5535 - pearson_correlation_f: 0.1595 - val_loss: 0.5759 - val_acc: 0.6922 - val_pearson_correlation_f: 0.4956
Epoch 2/60
48000/48000 [==============================] - 4s 84us/step - loss: 0.5341 - acc: 0.7238 - pearson_correlation_f: 0.5698 - val_loss: 0.4590 - val_acc: 0.7908 - val_pearson_correlation_f: 0.6541
Epoch 3/60
48000/48000 [==============================] - 4s 82us/step - loss: 0.4495 - acc: 0.7831 - pearson_correlation_f: 0.6749 - val_loss: 0.3982 - val_acc: 0.8135 - val_pearson_correlation_f: 0.7060
Epoch 4/60
48000/48000 [==============================] - 4s 81us/step - loss: 0.3957 - acc: 0.8187 - pearson_correlation_f: 0.7304 - val_loss: 0.3743 - val_acc: 0.8297 - val_pearson_correlation_f: 0.7356
Epoch 5/60
48000/48000 [==============================] - 4s 82us/step - loss: 0.3522 - acc: 0.8450 - pearson_correlation_f: 0.7705 - val_loss: 0.3396 - val_acc: 0.8537 - val_pearson_correlation_f: 0.7608
Epoch 6/60
48000/48000 [==============================] - 4s 80us/step - loss: 0.3146 - acc: 0.8649 - pearson_correlation_f: 0.8015 - val_loss: 0.3670 - val_acc: 0.8408 - val_pearson_correlation_f: 0.7566
Epoch 7/60
48000/48000 [==============================] - 4s 82us/step - loss: 0.2803 - acc: 0.8832 - pearson_correlation_f: 0.8284 - val_loss: 0.3354 - val_acc: 0.8562 - val_pearson_correlation_f: 0.7706
Epoch 8/60
48000/48000 [==============================] - 4s 81us/step - loss: 0.2511 - acc: 0.8957 - pearson_correlation_f: 0.8499 - val_loss: 0.3128 - val_acc: 0.8712 - val_pearson_correlation_f: 0.7880
Epoch 9/60
48000/48000 [==============================] - 4s 82us/step - loss: 0.2216 - acc: 0.9121 - pearson_correlation_f: 0.8714 - val_loss: 0.3692 - val_acc: 0.8483 - val_pearson_correlation_f: 0.7667
Epoch 10/60
48000/48000 [==============================] - 4s 81us/step - loss: 0.2012 - acc: 0.9192 - pearson_correlation_f: 0.8846 - val_loss: 0.3136 - val_acc: 0.8703 - val_pearson_correlation_f: 0.7926
Epoch 11/60
48000/48000 [==============================] - 4s 80us/step - loss: 0.1799 - acc: 0.9292 - pearson_correlation_f: 0.8990 - val_loss: 0.5825 - val_acc: 0.7988 - val_pearson_correlation_f: 0.7101
2018-12-10 03:25:00.282532: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
6000/6000 [==============================] - 0s 79us/step
Test result:  [0.5802447357972463, 0.798, 0.7107623136838277]
python3 main.py neg USE LSTM
Using TensorFlow backend.
Setting:  neg USE 30000 1 LSTM None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:26:38.072133: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:26:38.584221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:26:38.584855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:26:38.584882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:26:48.656825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:26:48.656865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:26:48.656873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:26:48.658744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 39s 821us/step - loss: 0.6833 - acc: 0.5494 - pearson_correlation_f: 0.1262 - val_loss: 0.6576 - val_acc: 0.5958 - val_pearson_correlation_f: 0.2790
Epoch 2/60
48000/48000 [==============================] - 24s 498us/step - loss: 0.6337 - acc: 0.6366 - pearson_correlation_f: 0.3389 - val_loss: 0.6047 - val_acc: 0.6583 - val_pearson_correlation_f: 0.4061
Epoch 3/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.5794 - acc: 0.6876 - pearson_correlation_f: 0.4575 - val_loss: 0.5528 - val_acc: 0.7083 - val_pearson_correlation_f: 0.5028
Epoch 4/60
48000/48000 [==============================] - 24s 499us/step - loss: 0.5356 - acc: 0.7246 - pearson_correlation_f: 0.5312 - val_loss: 0.5048 - val_acc: 0.7493 - val_pearson_correlation_f: 0.5795
Epoch 5/60
48000/48000 [==============================] - 24s 501us/step - loss: 0.4998 - acc: 0.7495 - pearson_correlation_f: 0.5821 - val_loss: 0.4813 - val_acc: 0.7642 - val_pearson_correlation_f: 0.6072
Epoch 6/60
48000/48000 [==============================] - 24s 499us/step - loss: 0.4760 - acc: 0.7636 - pearson_correlation_f: 0.6116 - val_loss: 0.4579 - val_acc: 0.7820 - val_pearson_correlation_f: 0.6347
Epoch 7/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.4543 - acc: 0.7789 - pearson_correlation_f: 0.6382 - val_loss: 0.4479 - val_acc: 0.7827 - val_pearson_correlation_f: 0.6459
Epoch 8/60
48000/48000 [==============================] - 24s 502us/step - loss: 0.4348 - acc: 0.7892 - pearson_correlation_f: 0.6596 - val_loss: 0.4291 - val_acc: 0.7952 - val_pearson_correlation_f: 0.6683
Epoch 9/60
48000/48000 [==============================] - 24s 501us/step - loss: 0.4157 - acc: 0.8012 - pearson_correlation_f: 0.6809 - val_loss: 0.4278 - val_acc: 0.7952 - val_pearson_correlation_f: 0.6733
Epoch 10/60
48000/48000 [==============================] - 24s 498us/step - loss: 0.4001 - acc: 0.8133 - pearson_correlation_f: 0.6973 - val_loss: 0.4094 - val_acc: 0.8107 - val_pearson_correlation_f: 0.6896
Epoch 11/60
48000/48000 [==============================] - 24s 501us/step - loss: 0.3856 - acc: 0.8233 - pearson_correlation_f: 0.7134 - val_loss: 0.3940 - val_acc: 0.8192 - val_pearson_correlation_f: 0.7034
Epoch 12/60
48000/48000 [==============================] - 24s 499us/step - loss: 0.3715 - acc: 0.8306 - pearson_correlation_f: 0.7271 - val_loss: 0.3921 - val_acc: 0.8117 - val_pearson_correlation_f: 0.7077
Epoch 13/60
48000/48000 [==============================] - 24s 499us/step - loss: 0.3599 - acc: 0.8376 - pearson_correlation_f: 0.7389 - val_loss: 0.3812 - val_acc: 0.8200 - val_pearson_correlation_f: 0.7158
Epoch 14/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.3476 - acc: 0.8447 - pearson_correlation_f: 0.7503 - val_loss: 0.3679 - val_acc: 0.8325 - val_pearson_correlation_f: 0.7295
Epoch 15/60
48000/48000 [==============================] - 24s 502us/step - loss: 0.3371 - acc: 0.8523 - pearson_correlation_f: 0.7603 - val_loss: 0.3653 - val_acc: 0.8308 - val_pearson_correlation_f: 0.7334
Epoch 16/60
48000/48000 [==============================] - 24s 498us/step - loss: 0.3269 - acc: 0.8552 - pearson_correlation_f: 0.7694 - val_loss: 0.3572 - val_acc: 0.8360 - val_pearson_correlation_f: 0.7411
Epoch 17/60
48000/48000 [==============================] - 24s 499us/step - loss: 0.3183 - acc: 0.8621 - pearson_correlation_f: 0.7784 - val_loss: 0.3718 - val_acc: 0.8303 - val_pearson_correlation_f: 0.7274
Epoch 18/60
48000/48000 [==============================] - 24s 503us/step - loss: 0.3098 - acc: 0.8657 - pearson_correlation_f: 0.7855 - val_loss: 0.3485 - val_acc: 0.8415 - val_pearson_correlation_f: 0.7485
Epoch 19/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.3015 - acc: 0.8711 - pearson_correlation_f: 0.7924 - val_loss: 0.3470 - val_acc: 0.8448 - val_pearson_correlation_f: 0.7516
Epoch 20/60
48000/48000 [==============================] - 24s 497us/step - loss: 0.2959 - acc: 0.8721 - pearson_correlation_f: 0.7970 - val_loss: 0.3435 - val_acc: 0.8478 - val_pearson_correlation_f: 0.7556
Epoch 21/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2879 - acc: 0.8773 - pearson_correlation_f: 0.8036 - val_loss: 0.3497 - val_acc: 0.8488 - val_pearson_correlation_f: 0.7541
Epoch 22/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2805 - acc: 0.8817 - pearson_correlation_f: 0.8100 - val_loss: 0.3446 - val_acc: 0.8448 - val_pearson_correlation_f: 0.7550
Epoch 23/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2754 - acc: 0.8829 - pearson_correlation_f: 0.8138 - val_loss: 0.3358 - val_acc: 0.8540 - val_pearson_correlation_f: 0.7636
Epoch 24/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2697 - acc: 0.8855 - pearson_correlation_f: 0.8189 - val_loss: 0.3332 - val_acc: 0.8553 - val_pearson_correlation_f: 0.7661
Epoch 25/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2632 - acc: 0.8885 - pearson_correlation_f: 0.8242 - val_loss: 0.3391 - val_acc: 0.8543 - val_pearson_correlation_f: 0.7647
Epoch 26/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2574 - acc: 0.8918 - pearson_correlation_f: 0.8288 - val_loss: 0.3361 - val_acc: 0.8533 - val_pearson_correlation_f: 0.7652
Epoch 27/60
48000/48000 [==============================] - 24s 500us/step - loss: 0.2518 - acc: 0.8944 - pearson_correlation_f: 0.8338 - val_loss: 0.3358 - val_acc: 0.8572 - val_pearson_correlation_f: 0.7677
6000/6000 [==============================] - 4s 627us/step
Test result:  [0.3445547213951747, 0.8498333333333333, 0.7644981568654379]
python3 main.py neg USE-Large FC
Using TensorFlow backend.
Setting:  neg USE-Large 30000 1 FC None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:39:05.066284: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:39:05.523875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:39:05.524534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:39:05.524557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:39:14.535604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:39:14.535645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:39:14.535654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:39:14.536696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 16s 326us/step - loss: 0.6243 - acc: 0.6180 - pearson_correlation_f: 0.2906 - val_loss: 0.4221 - val_acc: 0.8367 - val_pearson_correlation_f: 0.7154
Epoch 2/60
48000/48000 [==============================] - 3s 71us/step - loss: 0.3451 - acc: 0.8655 - pearson_correlation_f: 0.7810 - val_loss: 0.3073 - val_acc: 0.8882 - val_pearson_correlation_f: 0.8179
Epoch 3/60
48000/48000 [==============================] - 3s 71us/step - loss: 0.2178 - acc: 0.9230 - pearson_correlation_f: 0.8757 - val_loss: 0.2682 - val_acc: 0.8927 - val_pearson_correlation_f: 0.8366
Epoch 4/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.1495 - acc: 0.9498 - pearson_correlation_f: 0.9195 - val_loss: 0.2452 - val_acc: 0.9208 - val_pearson_correlation_f: 0.8670
Epoch 5/60
48000/48000 [==============================] - 3s 71us/step - loss: 0.1056 - acc: 0.9658 - pearson_correlation_f: 0.9451 - val_loss: 0.2376 - val_acc: 0.9202 - val_pearson_correlation_f: 0.8710
Epoch 6/60
48000/48000 [==============================] - 3s 70us/step - loss: 0.0790 - acc: 0.9753 - pearson_correlation_f: 0.9601 - val_loss: 0.2551 - val_acc: 0.9190 - val_pearson_correlation_f: 0.8702
Epoch 7/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.0614 - acc: 0.9807 - pearson_correlation_f: 0.9690 - val_loss: 0.2516 - val_acc: 0.9293 - val_pearson_correlation_f: 0.8810
Epoch 8/60
48000/48000 [==============================] - 3s 70us/step - loss: 0.0483 - acc: 0.9851 - pearson_correlation_f: 0.9760 - val_loss: 0.2613 - val_acc: 0.9308 - val_pearson_correlation_f: 0.8836
6000/6000 [==============================] - 0s 72us/step
Test result:  [0.24192185966670512, 0.935, 0.8904479316075643]
python3 main.py neg USE-Large CNN
Using TensorFlow backend.
Setting:  neg USE-Large 30000 1 CNN None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:41:08.479599: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:41:08.980844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:41:08.981477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:41:08.981503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:41:18.573155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:41:18.573195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:41:18.573204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:41:18.575283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 03:41:22.609390: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
48000/48000 [==============================] - 18s 383us/step - loss: 0.6454 - acc: 0.5965 - pearson_correlation_f: 0.2593 - val_loss: 0.4694 - val_acc: 0.8143 - val_pearson_correlation_f: 0.6753
Epoch 2/60
48000/48000 [==============================] - 4s 89us/step - loss: 0.4369 - acc: 0.8070 - pearson_correlation_f: 0.7147 - val_loss: 0.3534 - val_acc: 0.8543 - val_pearson_correlation_f: 0.7698
Epoch 3/60
48000/48000 [==============================] - 4s 89us/step - loss: 0.3497 - acc: 0.8536 - pearson_correlation_f: 0.7867 - val_loss: 0.2942 - val_acc: 0.8867 - val_pearson_correlation_f: 0.8164
Epoch 4/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.3036 - acc: 0.8766 - pearson_correlation_f: 0.8232 - val_loss: 0.3204 - val_acc: 0.8695 - val_pearson_correlation_f: 0.8023
Epoch 5/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.2629 - acc: 0.8946 - pearson_correlation_f: 0.8513 - val_loss: 0.2703 - val_acc: 0.8972 - val_pearson_correlation_f: 0.8392
Epoch 6/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.2330 - acc: 0.9078 - pearson_correlation_f: 0.8706 - val_loss: 0.3030 - val_acc: 0.8838 - val_pearson_correlation_f: 0.8234
Epoch 7/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.2095 - acc: 0.9181 - pearson_correlation_f: 0.8856 - val_loss: 0.2543 - val_acc: 0.9030 - val_pearson_correlation_f: 0.8472
Epoch 8/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.1886 - acc: 0.9281 - pearson_correlation_f: 0.8982 - val_loss: 0.2258 - val_acc: 0.9135 - val_pearson_correlation_f: 0.8625
Epoch 9/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.1667 - acc: 0.9361 - pearson_correlation_f: 0.9106 - val_loss: 0.2530 - val_acc: 0.9075 - val_pearson_correlation_f: 0.8533
Epoch 10/60
48000/48000 [==============================] - 4s 89us/step - loss: 0.1501 - acc: 0.9439 - pearson_correlation_f: 0.9205 - val_loss: 0.2210 - val_acc: 0.9205 - val_pearson_correlation_f: 0.8704
Epoch 11/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.1367 - acc: 0.9491 - pearson_correlation_f: 0.9284 - val_loss: 0.3995 - val_acc: 0.8500 - val_pearson_correlation_f: 0.7910
Epoch 12/60
48000/48000 [==============================] - 4s 89us/step - loss: 0.1235 - acc: 0.9547 - pearson_correlation_f: 0.9355 - val_loss: 0.2945 - val_acc: 0.9057 - val_pearson_correlation_f: 0.8517
Epoch 13/60
48000/48000 [==============================] - 4s 89us/step - loss: 0.1126 - acc: 0.9584 - pearson_correlation_f: 0.9408 - val_loss: 0.2345 - val_acc: 0.9217 - val_pearson_correlation_f: 0.8709
2018-12-10 03:42:17.978667: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
6000/6000 [==============================] - 1s 84us/step
Test result:  [0.24113508105278014, 0.9186666666666666, 0.870041491985321]
python3 main.py neg USE-Large LSTM
Using TensorFlow backend.
Setting:  neg USE-Large 30000 1 LSTM None
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:43:47.657426: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:43:48.260242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:43:48.260867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:43:48.260890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:43:57.928833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:43:57.928876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:43:57.928885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:43:57.931237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 37s 780us/step - loss: 0.6933 - acc: 0.5032 - pearson_correlation_f: 0.0054 - val_loss: 0.6929 - val_acc: 0.5155 - val_pearson_correlation_f: 0.0292
Epoch 2/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.6763 - acc: 0.5658 - pearson_correlation_f: 0.1818 - val_loss: 0.6471 - val_acc: 0.6088 - val_pearson_correlation_f: 0.3104
Epoch 3/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.6208 - acc: 0.6422 - pearson_correlation_f: 0.3686 - val_loss: 0.6061 - val_acc: 0.6637 - val_pearson_correlation_f: 0.4049
Epoch 4/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.5677 - acc: 0.7034 - pearson_correlation_f: 0.4741 - val_loss: 0.5534 - val_acc: 0.7115 - val_pearson_correlation_f: 0.4997
Epoch 5/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.5250 - acc: 0.7418 - pearson_correlation_f: 0.5414 - val_loss: 0.5232 - val_acc: 0.7445 - val_pearson_correlation_f: 0.5445
Epoch 6/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.4936 - acc: 0.7660 - pearson_correlation_f: 0.5876 - val_loss: 0.4969 - val_acc: 0.7642 - val_pearson_correlation_f: 0.5868
Epoch 7/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.4674 - acc: 0.7858 - pearson_correlation_f: 0.6238 - val_loss: 0.4768 - val_acc: 0.7805 - val_pearson_correlation_f: 0.6137
Epoch 8/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.4426 - acc: 0.8007 - pearson_correlation_f: 0.6547 - val_loss: 0.4582 - val_acc: 0.7915 - val_pearson_correlation_f: 0.6370
Epoch 9/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.4232 - acc: 0.8148 - pearson_correlation_f: 0.6776 - val_loss: 0.4414 - val_acc: 0.8033 - val_pearson_correlation_f: 0.6581
Epoch 10/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.4054 - acc: 0.8254 - pearson_correlation_f: 0.6981 - val_loss: 0.4209 - val_acc: 0.8165 - val_pearson_correlation_f: 0.6822
Epoch 11/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.3889 - acc: 0.8364 - pearson_correlation_f: 0.7159 - val_loss: 0.4199 - val_acc: 0.8170 - val_pearson_correlation_f: 0.6849
Epoch 12/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.3780 - acc: 0.8404 - pearson_correlation_f: 0.7273 - val_loss: 0.4037 - val_acc: 0.8293 - val_pearson_correlation_f: 0.7025
Epoch 13/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.3645 - acc: 0.8491 - pearson_correlation_f: 0.7412 - val_loss: 0.3842 - val_acc: 0.8382 - val_pearson_correlation_f: 0.7229
Epoch 14/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.3532 - acc: 0.8557 - pearson_correlation_f: 0.7524 - val_loss: 0.3710 - val_acc: 0.8480 - val_pearson_correlation_f: 0.7368
Epoch 15/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.3427 - acc: 0.8608 - pearson_correlation_f: 0.7627 - val_loss: 0.3728 - val_acc: 0.8427 - val_pearson_correlation_f: 0.7343
Epoch 16/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.3352 - acc: 0.8643 - pearson_correlation_f: 0.7696 - val_loss: 0.3691 - val_acc: 0.8490 - val_pearson_correlation_f: 0.7406
Epoch 17/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.3260 - acc: 0.8697 - pearson_correlation_f: 0.7790 - val_loss: 0.3601 - val_acc: 0.8547 - val_pearson_correlation_f: 0.7485
Epoch 18/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.3183 - acc: 0.8740 - pearson_correlation_f: 0.7855 - val_loss: 0.3609 - val_acc: 0.8475 - val_pearson_correlation_f: 0.7463
Epoch 19/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.3148 - acc: 0.8745 - pearson_correlation_f: 0.7880 - val_loss: 0.3484 - val_acc: 0.8595 - val_pearson_correlation_f: 0.7615
Epoch 20/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.3038 - acc: 0.8819 - pearson_correlation_f: 0.7988 - val_loss: 0.3371 - val_acc: 0.8670 - val_pearson_correlation_f: 0.7710
Epoch 21/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.2952 - acc: 0.8866 - pearson_correlation_f: 0.8065 - val_loss: 0.3367 - val_acc: 0.8630 - val_pearson_correlation_f: 0.7702
Epoch 22/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.2880 - acc: 0.8879 - pearson_correlation_f: 0.8117 - val_loss: 0.3361 - val_acc: 0.8665 - val_pearson_correlation_f: 0.7735
Epoch 23/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.2802 - acc: 0.8923 - pearson_correlation_f: 0.8183 - val_loss: 0.3253 - val_acc: 0.8697 - val_pearson_correlation_f: 0.7814
Epoch 24/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.2777 - acc: 0.8927 - pearson_correlation_f: 0.8203 - val_loss: 0.3246 - val_acc: 0.8737 - val_pearson_correlation_f: 0.7831
Epoch 25/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.2748 - acc: 0.8950 - pearson_correlation_f: 0.8224 - val_loss: 0.3267 - val_acc: 0.8752 - val_pearson_correlation_f: 0.7826
Epoch 26/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.2677 - acc: 0.8980 - pearson_correlation_f: 0.8281 - val_loss: 0.3180 - val_acc: 0.8805 - val_pearson_correlation_f: 0.7899
Epoch 27/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.2630 - acc: 0.8992 - pearson_correlation_f: 0.8318 - val_loss: 0.3287 - val_acc: 0.8708 - val_pearson_correlation_f: 0.7806
Epoch 28/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.2601 - acc: 0.9000 - pearson_correlation_f: 0.8338 - val_loss: 0.3172 - val_acc: 0.8810 - val_pearson_correlation_f: 0.7913
Epoch 29/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.2514 - acc: 0.9061 - pearson_correlation_f: 0.8415 - val_loss: 0.3115 - val_acc: 0.8758 - val_pearson_correlation_f: 0.7951
Epoch 30/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.2450 - acc: 0.9081 - pearson_correlation_f: 0.8465 - val_loss: 0.3115 - val_acc: 0.8803 - val_pearson_correlation_f: 0.7980
Epoch 31/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.2412 - acc: 0.9098 - pearson_correlation_f: 0.8489 - val_loss: 0.3054 - val_acc: 0.8838 - val_pearson_correlation_f: 0.8026
Epoch 32/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.2392 - acc: 0.9104 - pearson_correlation_f: 0.8504 - val_loss: 0.3082 - val_acc: 0.8833 - val_pearson_correlation_f: 0.8000
Epoch 33/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.2427 - acc: 0.9083 - pearson_correlation_f: 0.8468 - val_loss: 0.3114 - val_acc: 0.8802 - val_pearson_correlation_f: 0.7969
Epoch 34/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.2405 - acc: 0.9082 - pearson_correlation_f: 0.8486 - val_loss: 0.3090 - val_acc: 0.8843 - val_pearson_correlation_f: 0.8007
6000/6000 [==============================] - 4s 605us/step
Test result:  [0.29562559533119204, 0.882, 0.8097617222468059]
EXP 2
Mon Dec 10 03:57:38 CST 2018
python3 main.py mutate glove FC --extra=add
Using TensorFlow backend.
Setting:  mutate glove 30000 1 FC add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14555600  
_________________________________________________________________
flatten_1 (Flatten)          (None, 114600)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               14668928  
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 29,224,657
Trainable params: 14,669,057
Non-trainable params: 14,555,600
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:58:30.996394: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:58:31.091105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:58:31.091545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:58:31.091561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:58:31.246450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:58:31.246488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:58:31.246493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:58:31.246636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 5s 103us/step - loss: 0.4132 - mean_absolute_error: 0.3828 - mean_squared_error: 0.4132 - acc: 0.4045 - pearson_correlation_f: 0.2870 - val_loss: 0.1006 - val_mean_absolute_error: 0.2331 - val_mean_squared_error: 0.1006 - val_acc: 0.5000 - val_pearson_correlation_f: 0.5288
Epoch 2/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0802 - mean_absolute_error: 0.2274 - mean_squared_error: 0.0802 - acc: 0.4844 - pearson_correlation_f: 0.6694 - val_loss: 0.0743 - val_mean_absolute_error: 0.2412 - val_mean_squared_error: 0.0743 - val_acc: 0.4837 - val_pearson_correlation_f: 0.7303
Epoch 3/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0634 - mean_absolute_error: 0.1999 - mean_squared_error: 0.0634 - acc: 0.4864 - pearson_correlation_f: 0.7864 - val_loss: 0.0567 - val_mean_absolute_error: 0.2039 - val_mean_squared_error: 0.0567 - val_acc: 0.4927 - val_pearson_correlation_f: 0.7727
Epoch 4/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0528 - mean_absolute_error: 0.1834 - mean_squared_error: 0.0528 - acc: 0.4902 - pearson_correlation_f: 0.8313 - val_loss: 0.0502 - val_mean_absolute_error: 0.1888 - val_mean_squared_error: 0.0502 - val_acc: 0.4948 - val_pearson_correlation_f: 0.7883
Epoch 5/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0476 - mean_absolute_error: 0.1753 - mean_squared_error: 0.0476 - acc: 0.4937 - pearson_correlation_f: 0.8573 - val_loss: 0.0569 - val_mean_absolute_error: 0.1817 - val_mean_squared_error: 0.0569 - val_acc: 0.4992 - val_pearson_correlation_f: 0.7456
Epoch 6/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0431 - mean_absolute_error: 0.1667 - mean_squared_error: 0.0431 - acc: 0.4936 - pearson_correlation_f: 0.8732 - val_loss: 0.0605 - val_mean_absolute_error: 0.1908 - val_mean_squared_error: 0.0605 - val_acc: 0.4988 - val_pearson_correlation_f: 0.8010
Epoch 7/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0399 - mean_absolute_error: 0.1609 - mean_squared_error: 0.0399 - acc: 0.4955 - pearson_correlation_f: 0.8865 - val_loss: 0.0631 - val_mean_absolute_error: 0.2117 - val_mean_squared_error: 0.0631 - val_acc: 0.4817 - val_pearson_correlation_f: 0.7911
6000/6000 [==============================] - 0s 71us/step
Test result:  [0.06410705144206683, 0.21276087109247843, 0.06410705144206683, 0.47933333333333333, 0.7938274478912354]
python3 main.py mutate glove FC --extra=delete
Using TensorFlow backend.
Setting:  mutate glove 30000 1 FC delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14514900  
_________________________________________________________________
flatten_1 (Flatten)          (None, 114600)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               14668928  
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 29,183,957
Trainable params: 14,669,057
Non-trainable params: 14,514,900
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 03:59:51.935807: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 03:59:52.029620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 03:59:52.030057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 03:59:52.030073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 03:59:52.187138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 03:59:52.187173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 03:59:52.187178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 03:59:52.187325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 5s 104us/step - loss: 1.4211 - mean_absolute_error: 0.4547 - mean_squared_error: 1.4211 - acc: 0.3805 - pearson_correlation_f: 0.5907 - val_loss: 0.0776 - val_mean_absolute_error: 0.1522 - val_mean_squared_error: 0.0776 - val_acc: 0.4983 - val_pearson_correlation_f: 0.8546
Epoch 2/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0359 - mean_absolute_error: 0.1526 - mean_squared_error: 0.0359 - acc: 0.4937 - pearson_correlation_f: 0.8899 - val_loss: 0.0678 - val_mean_absolute_error: 0.1445 - val_mean_squared_error: 0.0678 - val_acc: 0.4893 - val_pearson_correlation_f: 0.8763
Epoch 3/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0291 - mean_absolute_error: 0.1368 - mean_squared_error: 0.0291 - acc: 0.4966 - pearson_correlation_f: 0.9146 - val_loss: 0.0615 - val_mean_absolute_error: 0.1361 - val_mean_squared_error: 0.0615 - val_acc: 0.4923 - val_pearson_correlation_f: 0.8822
Epoch 4/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0257 - mean_absolute_error: 0.1283 - mean_squared_error: 0.0257 - acc: 0.4975 - pearson_correlation_f: 0.9283 - val_loss: 0.0687 - val_mean_absolute_error: 0.1531 - val_mean_squared_error: 0.0687 - val_acc: 0.4897 - val_pearson_correlation_f: 0.8784
Epoch 5/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0236 - mean_absolute_error: 0.1225 - mean_squared_error: 0.0236 - acc: 0.4982 - pearson_correlation_f: 0.9364 - val_loss: 0.0602 - val_mean_absolute_error: 0.1307 - val_mean_squared_error: 0.0602 - val_acc: 0.4920 - val_pearson_correlation_f: 0.8847
Epoch 6/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0220 - mean_absolute_error: 0.1190 - mean_squared_error: 0.0220 - acc: 0.4983 - pearson_correlation_f: 0.9420 - val_loss: 0.0689 - val_mean_absolute_error: 0.1622 - val_mean_squared_error: 0.0689 - val_acc: 0.4982 - val_pearson_correlation_f: 0.8829
Epoch 7/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0211 - mean_absolute_error: 0.1167 - mean_squared_error: 0.0211 - acc: 0.4990 - pearson_correlation_f: 0.9463 - val_loss: 0.0676 - val_mean_absolute_error: 0.1551 - val_mean_squared_error: 0.0676 - val_acc: 0.4983 - val_pearson_correlation_f: 0.8803
Epoch 8/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0198 - mean_absolute_error: 0.1127 - mean_squared_error: 0.0198 - acc: 0.4991 - pearson_correlation_f: 0.9498 - val_loss: 0.0696 - val_mean_absolute_error: 0.1595 - val_mean_squared_error: 0.0696 - val_acc: 0.4980 - val_pearson_correlation_f: 0.8842
6000/6000 [==============================] - 0s 70us/step
Test result:  [0.03732204906642437, 0.15762860929965972, 0.03732204906642437, 0.49783333333333335, 0.9000800665219625]
python3 main.py mutate glove FC --extra=replace
Using TensorFlow backend.
Setting:  mutate glove 30000 1 FC replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14497900  
_________________________________________________________________
flatten_1 (Flatten)          (None, 114600)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               14668928  
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 29,166,957
Trainable params: 14,669,057
Non-trainable params: 14,497,900
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 04:01:16.949721: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 04:01:17.045920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 04:01:17.046450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 04:01:17.046466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 04:01:17.202278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 04:01:17.202323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 04:01:17.202329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 04:01:17.202487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 5s 104us/step - loss: 0.5467 - mean_absolute_error: 0.3994 - mean_squared_error: 0.5467 - acc: 0.3832 - pearson_correlation_f: 0.4570 - val_loss: 0.0760 - val_mean_absolute_error: 0.2087 - val_mean_squared_error: 0.0760 - val_acc: 0.4997 - val_pearson_correlation_f: 0.7276
Epoch 2/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.0579 - mean_absolute_error: 0.1912 - mean_squared_error: 0.0579 - acc: 0.4839 - pearson_correlation_f: 0.8203 - val_loss: 0.0408 - val_mean_absolute_error: 0.1646 - val_mean_squared_error: 0.0408 - val_acc: 0.4893 - val_pearson_correlation_f: 0.8527
Epoch 3/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0400 - mean_absolute_error: 0.1618 - mean_squared_error: 0.0400 - acc: 0.4934 - pearson_correlation_f: 0.8882 - val_loss: 0.0403 - val_mean_absolute_error: 0.1620 - val_mean_squared_error: 0.0403 - val_acc: 0.4987 - val_pearson_correlation_f: 0.8717
Epoch 4/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0330 - mean_absolute_error: 0.1472 - mean_squared_error: 0.0330 - acc: 0.4964 - pearson_correlation_f: 0.9147 - val_loss: 0.0312 - val_mean_absolute_error: 0.1392 - val_mean_squared_error: 0.0312 - val_acc: 0.4978 - val_pearson_correlation_f: 0.8721
Epoch 5/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0288 - mean_absolute_error: 0.1387 - mean_squared_error: 0.0288 - acc: 0.4979 - pearson_correlation_f: 0.9276 - val_loss: 0.0705 - val_mean_absolute_error: 0.2236 - val_mean_squared_error: 0.0705 - val_acc: 0.4663 - val_pearson_correlation_f: 0.8577
Epoch 6/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0265 - mean_absolute_error: 0.1332 - mean_squared_error: 0.0265 - acc: 0.4986 - pearson_correlation_f: 0.9367 - val_loss: 0.0288 - val_mean_absolute_error: 0.1346 - val_mean_squared_error: 0.0288 - val_acc: 0.4973 - val_pearson_correlation_f: 0.8788
Epoch 7/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0241 - mean_absolute_error: 0.1268 - mean_squared_error: 0.0241 - acc: 0.4988 - pearson_correlation_f: 0.9433 - val_loss: 0.0340 - val_mean_absolute_error: 0.1439 - val_mean_squared_error: 0.0340 - val_acc: 0.4905 - val_pearson_correlation_f: 0.8773
Epoch 8/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0229 - mean_absolute_error: 0.1249 - mean_squared_error: 0.0229 - acc: 0.4992 - pearson_correlation_f: 0.9481 - val_loss: 0.0359 - val_mean_absolute_error: 0.1482 - val_mean_squared_error: 0.0359 - val_acc: 0.4895 - val_pearson_correlation_f: 0.8759
Epoch 9/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0218 - mean_absolute_error: 0.1220 - mean_squared_error: 0.0218 - acc: 0.4996 - pearson_correlation_f: 0.9510 - val_loss: 0.0410 - val_mean_absolute_error: 0.1613 - val_mean_squared_error: 0.0410 - val_acc: 0.4868 - val_pearson_correlation_f: 0.8713
6000/6000 [==============================] - 0s 72us/step
Test result:  [0.04019303824504217, 0.16045216691493988, 0.04019303824504217, 0.488, 0.8771585040092468]
python3 main.py mutate glove CNN --extra=add
Using TensorFlow backend.
Setting:  mutate glove 30000 1 CNN add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14483700  
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1142, 128)         64128     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 380, 128)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,564,469
Trainable params: 80,769
Non-trainable params: 14,483,700
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 04:02:47.526937: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 04:02:47.623913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 04:02:47.624360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 04:02:47.624378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 04:02:47.780559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 04:02:47.780597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 04:02:47.780602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 04:02:47.780747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 14s 296us/step - loss: 0.2307 - mean_absolute_error: 0.3677 - mean_squared_error: 0.2307 - acc: 0.3785 - pearson_correlation_f: 0.3619 - val_loss: 0.0617 - val_mean_absolute_error: 0.2050 - val_mean_squared_error: 0.0617 - val_acc: 0.4818 - val_pearson_correlation_f: 0.6889
Epoch 2/60
48000/48000 [==============================] - 12s 256us/step - loss: 0.0582 - mean_absolute_error: 0.1854 - mean_squared_error: 0.0582 - acc: 0.4891 - pearson_correlation_f: 0.7386 - val_loss: 0.0456 - val_mean_absolute_error: 0.1583 - val_mean_squared_error: 0.0456 - val_acc: 0.4967 - val_pearson_correlation_f: 0.7488
Epoch 3/60
48000/48000 [==============================] - 12s 257us/step - loss: 0.0451 - mean_absolute_error: 0.1604 - mean_squared_error: 0.0451 - acc: 0.4941 - pearson_correlation_f: 0.8014 - val_loss: 0.0900 - val_mean_absolute_error: 0.2313 - val_mean_squared_error: 0.0900 - val_acc: 0.4997 - val_pearson_correlation_f: 0.7561
Epoch 4/60
48000/48000 [==============================] - 12s 258us/step - loss: 0.0385 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0385 - acc: 0.4956 - pearson_correlation_f: 0.8379 - val_loss: 0.0424 - val_mean_absolute_error: 0.1587 - val_mean_squared_error: 0.0424 - val_acc: 0.4917 - val_pearson_correlation_f: 0.7793
Epoch 5/60
48000/48000 [==============================] - 13s 265us/step - loss: 0.0337 - mean_absolute_error: 0.1362 - mean_squared_error: 0.0337 - acc: 0.4971 - pearson_correlation_f: 0.8614 - val_loss: 0.0502 - val_mean_absolute_error: 0.1560 - val_mean_squared_error: 0.0502 - val_acc: 0.4982 - val_pearson_correlation_f: 0.7819
Epoch 6/60
48000/48000 [==============================] - 13s 269us/step - loss: 0.0300 - mean_absolute_error: 0.1281 - mean_squared_error: 0.0300 - acc: 0.4980 - pearson_correlation_f: 0.8805 - val_loss: 0.0413 - val_mean_absolute_error: 0.1489 - val_mean_squared_error: 0.0413 - val_acc: 0.4897 - val_pearson_correlation_f: 0.7855
Epoch 7/60
48000/48000 [==============================] - 13s 270us/step - loss: 0.0266 - mean_absolute_error: 0.1203 - mean_squared_error: 0.0266 - acc: 0.4987 - pearson_correlation_f: 0.8957 - val_loss: 0.0465 - val_mean_absolute_error: 0.1434 - val_mean_squared_error: 0.0465 - val_acc: 0.4982 - val_pearson_correlation_f: 0.7815
Epoch 8/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.0244 - mean_absolute_error: 0.1147 - mean_squared_error: 0.0244 - acc: 0.4986 - pearson_correlation_f: 0.9063 - val_loss: 0.0411 - val_mean_absolute_error: 0.1429 - val_mean_squared_error: 0.0411 - val_acc: 0.4905 - val_pearson_correlation_f: 0.7880
Epoch 9/60
48000/48000 [==============================] - 13s 274us/step - loss: 0.0226 - mean_absolute_error: 0.1104 - mean_squared_error: 0.0226 - acc: 0.4989 - pearson_correlation_f: 0.9152 - val_loss: 0.0412 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0412 - val_acc: 0.4947 - val_pearson_correlation_f: 0.7826
Epoch 10/60
48000/48000 [==============================] - 13s 274us/step - loss: 0.0206 - mean_absolute_error: 0.1052 - mean_squared_error: 0.0206 - acc: 0.4992 - pearson_correlation_f: 0.9230 - val_loss: 0.0437 - val_mean_absolute_error: 0.1508 - val_mean_squared_error: 0.0437 - val_acc: 0.4875 - val_pearson_correlation_f: 0.7872
Epoch 11/60
48000/48000 [==============================] - 13s 274us/step - loss: 0.0194 - mean_absolute_error: 0.1022 - mean_squared_error: 0.0194 - acc: 0.4991 - pearson_correlation_f: 0.9293 - val_loss: 0.0437 - val_mean_absolute_error: 0.1396 - val_mean_squared_error: 0.0437 - val_acc: 0.4955 - val_pearson_correlation_f: 0.7794
6000/6000 [==============================] - 1s 128us/step
Test result:  [0.04209888771673043, 0.13599625569581986, 0.04209888771673043, 0.49733333333333335, 0.7945005915959676]
python3 main.py mutate glove CNN --extra=delete
Using TensorFlow backend.
Setting:  mutate glove 30000 1 CNN delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14431300  
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1142, 128)         64128     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 380, 128)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,512,069
Trainable params: 80,769
Non-trainable params: 14,431,300
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 04:06:01.178988: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 04:06:01.271651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 04:06:01.272096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 04:06:01.272112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 04:06:01.430001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 04:06:01.430039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 04:06:01.430051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 04:06:01.430195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 14s 284us/step - loss: 0.2067 - mean_absolute_error: 0.3644 - mean_squared_error: 0.2067 - acc: 0.4046 - pearson_correlation_f: 0.0142 - val_loss: 0.1061 - val_mean_absolute_error: 0.2792 - val_mean_squared_error: 0.1061 - val_acc: 0.4998 - val_pearson_correlation_f: 0.1067
Epoch 2/60
48000/48000 [==============================] - 12s 256us/step - loss: 0.1015 - mean_absolute_error: 0.2681 - mean_squared_error: 0.1015 - acc: 0.4968 - pearson_correlation_f: 0.2559 - val_loss: 0.0958 - val_mean_absolute_error: 0.2420 - val_mean_squared_error: 0.0958 - val_acc: 0.5000 - val_pearson_correlation_f: 0.3802
Epoch 3/60
48000/48000 [==============================] - 12s 258us/step - loss: 0.0887 - mean_absolute_error: 0.2457 - mean_squared_error: 0.0887 - acc: 0.4932 - pearson_correlation_f: 0.4306 - val_loss: 0.0882 - val_mean_absolute_error: 0.2311 - val_mean_squared_error: 0.0882 - val_acc: 0.4993 - val_pearson_correlation_f: 0.4531
Epoch 4/60
48000/48000 [==============================] - 12s 259us/step - loss: 0.0808 - mean_absolute_error: 0.2319 - mean_squared_error: 0.0808 - acc: 0.4912 - pearson_correlation_f: 0.5069 - val_loss: 0.0816 - val_mean_absolute_error: 0.2290 - val_mean_squared_error: 0.0816 - val_acc: 0.4948 - val_pearson_correlation_f: 0.4854
Epoch 5/60
48000/48000 [==============================] - 13s 268us/step - loss: 0.0753 - mean_absolute_error: 0.2221 - mean_squared_error: 0.0753 - acc: 0.4906 - pearson_correlation_f: 0.5577 - val_loss: 0.0798 - val_mean_absolute_error: 0.2279 - val_mean_squared_error: 0.0798 - val_acc: 0.4883 - val_pearson_correlation_f: 0.5047
Epoch 6/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.0699 - mean_absolute_error: 0.2125 - mean_squared_error: 0.0699 - acc: 0.4907 - pearson_correlation_f: 0.6017 - val_loss: 0.0888 - val_mean_absolute_error: 0.2523 - val_mean_squared_error: 0.0888 - val_acc: 0.4643 - val_pearson_correlation_f: 0.5056
Epoch 7/60
48000/48000 [==============================] - 13s 271us/step - loss: 0.0654 - mean_absolute_error: 0.2049 - mean_squared_error: 0.0654 - acc: 0.4909 - pearson_correlation_f: 0.6353 - val_loss: 0.0795 - val_mean_absolute_error: 0.2219 - val_mean_squared_error: 0.0795 - val_acc: 0.4890 - val_pearson_correlation_f: 0.5158
Epoch 8/60
48000/48000 [==============================] - 13s 276us/step - loss: 0.0618 - mean_absolute_error: 0.1984 - mean_squared_error: 0.0618 - acc: 0.4910 - pearson_correlation_f: 0.6656 - val_loss: 0.0814 - val_mean_absolute_error: 0.2337 - val_mean_squared_error: 0.0814 - val_acc: 0.4800 - val_pearson_correlation_f: 0.5138
Epoch 9/60
48000/48000 [==============================] - 13s 272us/step - loss: 0.0580 - mean_absolute_error: 0.1911 - mean_squared_error: 0.0580 - acc: 0.4919 - pearson_correlation_f: 0.6900 - val_loss: 0.0836 - val_mean_absolute_error: 0.2286 - val_mean_squared_error: 0.0836 - val_acc: 0.4745 - val_pearson_correlation_f: 0.5121
Epoch 10/60
48000/48000 [==============================] - 13s 270us/step - loss: 0.0555 - mean_absolute_error: 0.1864 - mean_squared_error: 0.0555 - acc: 0.4922 - pearson_correlation_f: 0.7126 - val_loss: 0.0820 - val_mean_absolute_error: 0.2239 - val_mean_squared_error: 0.0820 - val_acc: 0.4833 - val_pearson_correlation_f: 0.5091
6000/6000 [==============================] - 1s 129us/step
Test result:  [0.08547975447773934, 0.22736195063591003, 0.08547975447773934, 0.4821666666666667, 0.48828520701328915]
python3 main.py mutate glove CNN --extra=replace
Using TensorFlow backend.
Setting:  mutate glove 30000 1 CNN replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14542000  
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1142, 128)         64128     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 380, 128)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,622,769
Trainable params: 80,769
Non-trainable params: 14,542,000
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 04:09:02.297852: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 04:09:02.396222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 04:09:02.396702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 04:09:02.396718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 04:09:02.559225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 04:09:02.559260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 04:09:02.559265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 04:09:02.559407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 14s 288us/step - loss: 0.1937 - mean_absolute_error: 0.3303 - mean_squared_error: 0.1937 - acc: 0.4005 - pearson_correlation_f: 0.4832 - val_loss: 0.0433 - val_mean_absolute_error: 0.1640 - val_mean_squared_error: 0.0433 - val_acc: 0.4897 - val_pearson_correlation_f: 0.7904
Epoch 2/60
48000/48000 [==============================] - 12s 257us/step - loss: 0.0423 - mean_absolute_error: 0.1564 - mean_squared_error: 0.0423 - acc: 0.4933 - pearson_correlation_f: 0.8269 - val_loss: 0.0351 - val_mean_absolute_error: 0.1356 - val_mean_squared_error: 0.0351 - val_acc: 0.4983 - val_pearson_correlation_f: 0.8365
Epoch 3/60
48000/48000 [==============================] - 12s 258us/step - loss: 0.0314 - mean_absolute_error: 0.1333 - mean_squared_error: 0.0314 - acc: 0.4972 - pearson_correlation_f: 0.8695 - val_loss: 0.0295 - val_mean_absolute_error: 0.1258 - val_mean_squared_error: 0.0295 - val_acc: 0.4980 - val_pearson_correlation_f: 0.8476
Epoch 4/60
48000/48000 [==============================] - 13s 262us/step - loss: 0.0262 - mean_absolute_error: 0.1212 - mean_squared_error: 0.0262 - acc: 0.4985 - pearson_correlation_f: 0.8931 - val_loss: 0.0316 - val_mean_absolute_error: 0.1352 - val_mean_squared_error: 0.0316 - val_acc: 0.4950 - val_pearson_correlation_f: 0.8560
Epoch 5/60
48000/48000 [==============================] - 13s 268us/step - loss: 0.0226 - mean_absolute_error: 0.1124 - mean_squared_error: 0.0226 - acc: 0.4991 - pearson_correlation_f: 0.9101 - val_loss: 0.0288 - val_mean_absolute_error: 0.1191 - val_mean_squared_error: 0.0288 - val_acc: 0.4988 - val_pearson_correlation_f: 0.8589
Epoch 6/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.0200 - mean_absolute_error: 0.1061 - mean_squared_error: 0.0200 - acc: 0.4996 - pearson_correlation_f: 0.9216 - val_loss: 0.0273 - val_mean_absolute_error: 0.1147 - val_mean_squared_error: 0.0273 - val_acc: 0.4965 - val_pearson_correlation_f: 0.8612
Epoch 7/60
48000/48000 [==============================] - 13s 273us/step - loss: 0.0181 - mean_absolute_error: 0.1005 - mean_squared_error: 0.0181 - acc: 0.4996 - pearson_correlation_f: 0.9301 - val_loss: 0.0315 - val_mean_absolute_error: 0.1238 - val_mean_squared_error: 0.0315 - val_acc: 0.4985 - val_pearson_correlation_f: 0.8581
Epoch 8/60
48000/48000 [==============================] - 13s 274us/step - loss: 0.0162 - mean_absolute_error: 0.0954 - mean_squared_error: 0.0162 - acc: 0.4997 - pearson_correlation_f: 0.9382 - val_loss: 0.0389 - val_mean_absolute_error: 0.1402 - val_mean_squared_error: 0.0389 - val_acc: 0.4998 - val_pearson_correlation_f: 0.8557
Epoch 9/60
48000/48000 [==============================] - 13s 274us/step - loss: 0.0149 - mean_absolute_error: 0.0914 - mean_squared_error: 0.0149 - acc: 0.4997 - pearson_correlation_f: 0.9440 - val_loss: 0.0300 - val_mean_absolute_error: 0.1235 - val_mean_squared_error: 0.0300 - val_acc: 0.4943 - val_pearson_correlation_f: 0.8615
6000/6000 [==============================] - 1s 129us/step
Test result:  [0.029884631355603535, 0.12398686639467875, 0.029884631355603535, 0.49416666666666664, 0.8627641698519389]
python3 main.py mutate glove LSTM --extra=add
Using TensorFlow backend.
Setting:  mutate glove 30000 1 LSTM add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14514000  
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               117248    
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,631,377
Trainable params: 117,377
Non-trainable params: 14,514,000
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 04:11:51.377012: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 04:11:51.467681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 04:11:51.468135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 04:11:51.468151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 04:11:51.622527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 04:11:51.622565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 04:11:51.622571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 04:11:51.622704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 437s 9ms/step - loss: 0.1220 - mean_absolute_error: 0.2601 - mean_squared_error: 0.1220 - acc: 0.4201 - pearson_correlation_f: 0.4927 - val_loss: 0.0342 - val_mean_absolute_error: 0.1295 - val_mean_squared_error: 0.0342 - val_acc: 0.4993 - val_pearson_correlation_f: 0.8602
Epoch 2/60
48000/48000 [==============================] - 437s 9ms/step - loss: 0.0262 - mean_absolute_error: 0.1146 - mean_squared_error: 0.0262 - acc: 0.4980 - pearson_correlation_f: 0.8834 - val_loss: 0.0197 - val_mean_absolute_error: 0.0962 - val_mean_squared_error: 0.0197 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9036
Epoch 3/60
48000/48000 [==============================] - 436s 9ms/step - loss: 0.0199 - mean_absolute_error: 0.0967 - mean_squared_error: 0.0199 - acc: 0.4993 - pearson_correlation_f: 0.9083 - val_loss: 0.0180 - val_mean_absolute_error: 0.0892 - val_mean_squared_error: 0.0180 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9131
Epoch 4/60
48000/48000 [==============================] - 437s 9ms/step - loss: 0.0173 - mean_absolute_error: 0.0881 - mean_squared_error: 0.0173 - acc: 0.4994 - pearson_correlation_f: 0.9194 - val_loss: 0.0169 - val_mean_absolute_error: 0.0851 - val_mean_squared_error: 0.0169 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9196
Epoch 5/60
48000/48000 [==============================] - 435s 9ms/step - loss: 0.0157 - mean_absolute_error: 0.0830 - mean_squared_error: 0.0157 - acc: 0.4998 - pearson_correlation_f: 0.9262 - val_loss: 0.0164 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0164 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9191
Epoch 6/60
48000/48000 [==============================] - 437s 9ms/step - loss: 0.0145 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0145 - acc: 0.4999 - pearson_correlation_f: 0.9319 - val_loss: 0.0162 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0162 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9226
Epoch 7/60
48000/48000 [==============================] - 436s 9ms/step - loss: 0.0136 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0136 - acc: 0.4999 - pearson_correlation_f: 0.9364 - val_loss: 0.0182 - val_mean_absolute_error: 0.0964 - val_mean_squared_error: 0.0182 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9207
Epoch 8/60
48000/48000 [==============================] - 436s 9ms/step - loss: 0.0126 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0126 - acc: 0.4999 - pearson_correlation_f: 0.9410 - val_loss: 0.0159 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0159 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9244
Epoch 9/60
48000/48000 [==============================] - 437s 9ms/step - loss: 0.0117 - mean_absolute_error: 0.0703 - mean_squared_error: 0.0117 - acc: 0.5000 - pearson_correlation_f: 0.9449 - val_loss: 0.0155 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0155 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9242
Epoch 10/60
48000/48000 [==============================] - 437s 9ms/step - loss: 0.0109 - mean_absolute_error: 0.0676 - mean_squared_error: 0.0109 - acc: 0.5000 - pearson_correlation_f: 0.9490 - val_loss: 0.0161 - val_mean_absolute_error: 0.0817 - val_mean_squared_error: 0.0161 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9220
Epoch 11/60
48000/48000 [==============================] - 436s 9ms/step - loss: 0.0100 - mean_absolute_error: 0.0648 - mean_squared_error: 0.0100 - acc: 0.5000 - pearson_correlation_f: 0.9530 - val_loss: 0.0161 - val_mean_absolute_error: 0.0836 - val_mean_squared_error: 0.0161 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9200
Epoch 12/60
48000/48000 [==============================] - 436s 9ms/step - loss: 0.0092 - mean_absolute_error: 0.0622 - mean_squared_error: 0.0092 - acc: 0.5000 - pearson_correlation_f: 0.9569 - val_loss: 0.0190 - val_mean_absolute_error: 0.0826 - val_mean_squared_error: 0.0190 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9119
6000/6000 [==============================] - 65s 11ms/step
Test result:  [0.020075193827350936, 0.08316208686431249, 0.020075193827350936, 0.5, 0.9072862375577291]
python3 main.py mutate glove LSTM --extra=delete
Using TensorFlow backend.
Setting:  mutate glove 30000 1 LSTM delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14455900  
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               117248    
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,573,277
Trainable params: 117,377
Non-trainable params: 14,455,900
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 05:41:07.152774: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 05:41:07.245157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 05:41:07.245724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 05:41:07.245748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 05:41:07.409927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 05:41:07.409963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 05:41:07.409969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 05:41:07.410115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0808 - mean_absolute_error: 0.1905 - mean_squared_error: 0.0808 - acc: 0.4377 - pearson_correlation_f: 0.7837 - val_loss: 0.0206 - val_mean_absolute_error: 0.1210 - val_mean_squared_error: 0.0206 - val_acc: 0.4970 - val_pearson_correlation_f: 0.9227
Epoch 2/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0172 - mean_absolute_error: 0.0950 - mean_squared_error: 0.0172 - acc: 0.4971 - pearson_correlation_f: 0.9229 - val_loss: 0.0171 - val_mean_absolute_error: 0.0968 - val_mean_squared_error: 0.0171 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9262
Epoch 3/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0154 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0154 - acc: 0.4975 - pearson_correlation_f: 0.9280 - val_loss: 0.0143 - val_mean_absolute_error: 0.0863 - val_mean_squared_error: 0.0143 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9293
Epoch 4/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0148 - mean_absolute_error: 0.0851 - mean_squared_error: 0.0148 - acc: 0.4979 - pearson_correlation_f: 0.9300 - val_loss: 0.0144 - val_mean_absolute_error: 0.0855 - val_mean_squared_error: 0.0144 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9313
Epoch 5/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0141 - mean_absolute_error: 0.0823 - mean_squared_error: 0.0141 - acc: 0.4982 - pearson_correlation_f: 0.9322 - val_loss: 0.0200 - val_mean_absolute_error: 0.1039 - val_mean_squared_error: 0.0200 - val_acc: 0.4932 - val_pearson_correlation_f: 0.9224
Epoch 6/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0137 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0137 - acc: 0.4982 - pearson_correlation_f: 0.9343 - val_loss: 0.0142 - val_mean_absolute_error: 0.0776 - val_mean_squared_error: 0.0142 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9332
Epoch 7/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0132 - mean_absolute_error: 0.0790 - mean_squared_error: 0.0132 - acc: 0.4986 - pearson_correlation_f: 0.9362 - val_loss: 0.0134 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0134 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9343
Epoch 8/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0128 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0128 - acc: 0.4986 - pearson_correlation_f: 0.9382 - val_loss: 0.0133 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0133 - val_acc: 0.4980 - val_pearson_correlation_f: 0.9353
Epoch 9/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0123 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0123 - acc: 0.4988 - pearson_correlation_f: 0.9404 - val_loss: 0.0127 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0127 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9386
Epoch 10/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0118 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0118 - acc: 0.4989 - pearson_correlation_f: 0.9433 - val_loss: 0.0127 - val_mean_absolute_error: 0.0728 - val_mean_squared_error: 0.0127 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9389
Epoch 11/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0113 - mean_absolute_error: 0.0723 - mean_squared_error: 0.0113 - acc: 0.4990 - pearson_correlation_f: 0.9458 - val_loss: 0.0121 - val_mean_absolute_error: 0.0713 - val_mean_squared_error: 0.0121 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9413
Epoch 12/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0108 - mean_absolute_error: 0.0706 - mean_squared_error: 0.0108 - acc: 0.4993 - pearson_correlation_f: 0.9482 - val_loss: 0.0121 - val_mean_absolute_error: 0.0722 - val_mean_squared_error: 0.0121 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9411
Epoch 13/60
48000/48000 [==============================] - 440s 9ms/step - loss: 0.0102 - mean_absolute_error: 0.0685 - mean_squared_error: 0.0102 - acc: 0.4992 - pearson_correlation_f: 0.9510 - val_loss: 0.0118 - val_mean_absolute_error: 0.0703 - val_mean_squared_error: 0.0118 - val_acc: 0.4987 - val_pearson_correlation_f: 0.9422
Epoch 14/60
48000/48000 [==============================] - 440s 9ms/step - loss: 0.0097 - mean_absolute_error: 0.0667 - mean_squared_error: 0.0097 - acc: 0.4992 - pearson_correlation_f: 0.9534 - val_loss: 0.0123 - val_mean_absolute_error: 0.0738 - val_mean_squared_error: 0.0123 - val_acc: 0.4978 - val_pearson_correlation_f: 0.9418
Epoch 15/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0092 - mean_absolute_error: 0.0648 - mean_squared_error: 0.0092 - acc: 0.4994 - pearson_correlation_f: 0.9562 - val_loss: 0.0115 - val_mean_absolute_error: 0.0721 - val_mean_squared_error: 0.0115 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9450
Epoch 16/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0087 - mean_absolute_error: 0.0631 - mean_squared_error: 0.0087 - acc: 0.4995 - pearson_correlation_f: 0.9587 - val_loss: 0.0114 - val_mean_absolute_error: 0.0775 - val_mean_squared_error: 0.0114 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9453
Epoch 17/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0082 - mean_absolute_error: 0.0611 - mean_squared_error: 0.0082 - acc: 0.4996 - pearson_correlation_f: 0.9613 - val_loss: 0.0126 - val_mean_absolute_error: 0.0697 - val_mean_squared_error: 0.0126 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9391
Epoch 18/60
48000/48000 [==============================] - 441s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0077 - acc: 0.4995 - pearson_correlation_f: 0.9635 - val_loss: 0.0115 - val_mean_absolute_error: 0.0691 - val_mean_squared_error: 0.0115 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9437
Epoch 19/60
48000/48000 [==============================] - 442s 9ms/step - loss: 0.0072 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0072 - acc: 0.4997 - pearson_correlation_f: 0.9657 - val_loss: 0.0118 - val_mean_absolute_error: 0.0716 - val_mean_squared_error: 0.0118 - val_acc: 0.4978 - val_pearson_correlation_f: 0.9448
6000/6000 [==============================] - 68s 11ms/step
Test result:  [0.013055737530191739, 0.07344241261482239, 0.013055737530191739, 0.4955, 0.9365720845858256]
python3 main.py mutate glove LSTM --extra=replace
Using TensorFlow backend.
Setting:  mutate glove 30000 1 LSTM replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
creating tokenizer ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 1146) (48000,)
val:  (6000, 1146) (6000,)
test:  (6000, 1146) (6000,)
building model ..
Indexing word vectors.
Found 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1146)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 1146, 100)         14474300  
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               117248    
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129       
=================================================================
Total params: 14,591,677
Trainable params: 117,377
Non-trainable params: 14,474,300
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 08:02:51.660764: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 08:02:51.751953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 08:02:51.752402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 08:02:51.752419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 08:02:51.913699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 08:02:51.913737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 08:02:51.913743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 08:02:51.913905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0986 - mean_absolute_error: 0.2277 - mean_squared_error: 0.0986 - acc: 0.4302 - pearson_correlation_f: 0.6663 - val_loss: 0.0198 - val_mean_absolute_error: 0.0940 - val_mean_squared_error: 0.0198 - val_acc: 0.4995 - val_pearson_correlation_f: 0.9098
Epoch 2/60
48000/48000 [==============================] - 448s 9ms/step - loss: 0.0189 - mean_absolute_error: 0.0995 - mean_squared_error: 0.0189 - acc: 0.4988 - pearson_correlation_f: 0.9219 - val_loss: 0.0132 - val_mean_absolute_error: 0.0780 - val_mean_squared_error: 0.0132 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9376
Epoch 3/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0141 - mean_absolute_error: 0.0832 - mean_squared_error: 0.0141 - acc: 0.4995 - pearson_correlation_f: 0.9397 - val_loss: 0.0195 - val_mean_absolute_error: 0.1022 - val_mean_squared_error: 0.0195 - val_acc: 0.4977 - val_pearson_correlation_f: 0.9338
Epoch 4/60
48000/48000 [==============================] - 448s 9ms/step - loss: 0.0118 - mean_absolute_error: 0.0747 - mean_squared_error: 0.0118 - acc: 0.4997 - pearson_correlation_f: 0.9476 - val_loss: 0.0149 - val_mean_absolute_error: 0.0868 - val_mean_squared_error: 0.0149 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9437
Epoch 5/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0105 - mean_absolute_error: 0.0694 - mean_squared_error: 0.0105 - acc: 0.4999 - pearson_correlation_f: 0.9536 - val_loss: 0.0119 - val_mean_absolute_error: 0.0761 - val_mean_squared_error: 0.0119 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9517
Epoch 6/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0096 - mean_absolute_error: 0.0655 - mean_squared_error: 0.0096 - acc: 0.4999 - pearson_correlation_f: 0.9570 - val_loss: 0.0112 - val_mean_absolute_error: 0.0702 - val_mean_squared_error: 0.0112 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9524
Epoch 7/60
48000/48000 [==============================] - 448s 9ms/step - loss: 0.0087 - mean_absolute_error: 0.0624 - mean_squared_error: 0.0087 - acc: 0.5000 - pearson_correlation_f: 0.9609 - val_loss: 0.0111 - val_mean_absolute_error: 0.0694 - val_mean_squared_error: 0.0111 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9518
Epoch 8/60
48000/48000 [==============================] - 448s 9ms/step - loss: 0.0082 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0082 - acc: 0.5000 - pearson_correlation_f: 0.9631 - val_loss: 0.0111 - val_mean_absolute_error: 0.0677 - val_mean_squared_error: 0.0111 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9563
Epoch 9/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0078 - mean_absolute_error: 0.0580 - mean_squared_error: 0.0078 - acc: 0.5000 - pearson_correlation_f: 0.9652 - val_loss: 0.0090 - val_mean_absolute_error: 0.0585 - val_mean_squared_error: 0.0090 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9568
Epoch 10/60
48000/48000 [==============================] - 447s 9ms/step - loss: 0.0072 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0072 - acc: 0.5000 - pearson_correlation_f: 0.9674 - val_loss: 0.0098 - val_mean_absolute_error: 0.0723 - val_mean_squared_error: 0.0098 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9581
Epoch 11/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0068 - mean_absolute_error: 0.0542 - mean_squared_error: 0.0068 - acc: 0.5000 - pearson_correlation_f: 0.9691 - val_loss: 0.0091 - val_mean_absolute_error: 0.0584 - val_mean_squared_error: 0.0091 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9564
Epoch 12/60
48000/48000 [==============================] - 449s 9ms/step - loss: 0.0064 - mean_absolute_error: 0.0524 - mean_squared_error: 0.0064 - acc: 0.5000 - pearson_correlation_f: 0.9711 - val_loss: 0.0091 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0091 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9560
6000/6000 [==============================] - 66s 11ms/step
Test result:  [0.009017698476711909, 0.06351722197731335, 0.009017698476711909, 0.5, 0.9588094967206319]
python3 main.py mutate USE FC --extra=add
Using TensorFlow backend.
Setting:  mutate USE 30000 1 FC add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:35:01.259349: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:35:01.785017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:35:01.785543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:35:01.785562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:35:09.950021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:35:09.950062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:35:09.950070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:35:09.951079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 17s 350us/step - loss: 0.1223 - mean_absolute_error: 0.2722 - mean_squared_error: 0.1223 - acc: 0.4254 - pearson_correlation_f: 0.5095 - val_loss: 0.1026 - val_mean_absolute_error: 0.2585 - val_mean_squared_error: 0.1026 - val_acc: 0.4857 - val_pearson_correlation_f: 0.7458
Epoch 2/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0433 - mean_absolute_error: 0.1642 - mean_squared_error: 0.0433 - acc: 0.4961 - pearson_correlation_f: 0.8220 - val_loss: 0.0510 - val_mean_absolute_error: 0.1735 - val_mean_squared_error: 0.0510 - val_acc: 0.4982 - val_pearson_correlation_f: 0.8190
Epoch 3/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0347 - mean_absolute_error: 0.1465 - mean_squared_error: 0.0347 - acc: 0.4986 - pearson_correlation_f: 0.8490 - val_loss: 0.0318 - val_mean_absolute_error: 0.1412 - val_mean_squared_error: 0.0318 - val_acc: 0.4982 - val_pearson_correlation_f: 0.8411
Epoch 4/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0305 - mean_absolute_error: 0.1371 - mean_squared_error: 0.0305 - acc: 0.4991 - pearson_correlation_f: 0.8647 - val_loss: 0.0314 - val_mean_absolute_error: 0.1410 - val_mean_squared_error: 0.0314 - val_acc: 0.4985 - val_pearson_correlation_f: 0.8460
Epoch 5/60
48000/48000 [==============================] - 3s 66us/step - loss: 0.0278 - mean_absolute_error: 0.1305 - mean_squared_error: 0.0278 - acc: 0.4993 - pearson_correlation_f: 0.8745 - val_loss: 0.0305 - val_mean_absolute_error: 0.1353 - val_mean_squared_error: 0.0305 - val_acc: 0.4987 - val_pearson_correlation_f: 0.8429
Epoch 6/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.0260 - mean_absolute_error: 0.1262 - mean_squared_error: 0.0260 - acc: 0.4995 - pearson_correlation_f: 0.8825 - val_loss: 0.0314 - val_mean_absolute_error: 0.1406 - val_mean_squared_error: 0.0314 - val_acc: 0.4978 - val_pearson_correlation_f: 0.8446
Epoch 7/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0243 - mean_absolute_error: 0.1217 - mean_squared_error: 0.0243 - acc: 0.4996 - pearson_correlation_f: 0.8901 - val_loss: 0.0363 - val_mean_absolute_error: 0.1471 - val_mean_squared_error: 0.0363 - val_acc: 0.4983 - val_pearson_correlation_f: 0.8449
Epoch 8/60
48000/48000 [==============================] - 3s 70us/step - loss: 0.0229 - mean_absolute_error: 0.1182 - mean_squared_error: 0.0229 - acc: 0.4996 - pearson_correlation_f: 0.8960 - val_loss: 0.0306 - val_mean_absolute_error: 0.1371 - val_mean_squared_error: 0.0306 - val_acc: 0.4975 - val_pearson_correlation_f: 0.8470
6000/6000 [==============================] - 0s 82us/step
Test result:  [0.030424851700663568, 0.137946333527565, 0.030424851700663568, 0.49833333333333335, 0.8510145592689514]
python3 main.py mutate USE FC --extra=delete
Using TensorFlow backend.
Setting:  mutate USE 30000 1 FC delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:37:31.573598: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:37:32.073281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:37:32.073883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:37:32.073908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:37:40.502165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:37:40.502203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:37:40.502215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:37:40.503216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 17s 355us/step - loss: 0.1265 - mean_absolute_error: 0.2896 - mean_squared_error: 0.1265 - acc: 0.4225 - pearson_correlation_f: 0.3622 - val_loss: 0.1034 - val_mean_absolute_error: 0.2705 - val_mean_squared_error: 0.1034 - val_acc: 0.4028 - val_pearson_correlation_f: 0.5943
Epoch 2/60
48000/48000 [==============================] - 3s 72us/step - loss: 0.0702 - mean_absolute_error: 0.2165 - mean_squared_error: 0.0702 - acc: 0.4750 - pearson_correlation_f: 0.6263 - val_loss: 0.0595 - val_mean_absolute_error: 0.1987 - val_mean_squared_error: 0.0595 - val_acc: 0.4807 - val_pearson_correlation_f: 0.6652
Epoch 3/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.0608 - mean_absolute_error: 0.2004 - mean_squared_error: 0.0608 - acc: 0.4780 - pearson_correlation_f: 0.6790 - val_loss: 0.0583 - val_mean_absolute_error: 0.1949 - val_mean_squared_error: 0.0583 - val_acc: 0.4842 - val_pearson_correlation_f: 0.6840
Epoch 4/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.0546 - mean_absolute_error: 0.1887 - mean_squared_error: 0.0546 - acc: 0.4815 - pearson_correlation_f: 0.7159 - val_loss: 0.0557 - val_mean_absolute_error: 0.1885 - val_mean_squared_error: 0.0557 - val_acc: 0.4832 - val_pearson_correlation_f: 0.7022
Epoch 5/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.0494 - mean_absolute_error: 0.1782 - mean_squared_error: 0.0494 - acc: 0.4844 - pearson_correlation_f: 0.7480 - val_loss: 0.0578 - val_mean_absolute_error: 0.1924 - val_mean_squared_error: 0.0578 - val_acc: 0.4672 - val_pearson_correlation_f: 0.7188
Epoch 6/60
48000/48000 [==============================] - 3s 70us/step - loss: 0.0443 - mean_absolute_error: 0.1680 - mean_squared_error: 0.0443 - acc: 0.4881 - pearson_correlation_f: 0.7794 - val_loss: 0.0544 - val_mean_absolute_error: 0.1849 - val_mean_squared_error: 0.0544 - val_acc: 0.4845 - val_pearson_correlation_f: 0.7244
Epoch 7/60
48000/48000 [==============================] - 3s 69us/step - loss: 0.0395 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0395 - acc: 0.4914 - pearson_correlation_f: 0.8076 - val_loss: 0.0501 - val_mean_absolute_error: 0.1761 - val_mean_squared_error: 0.0501 - val_acc: 0.4823 - val_pearson_correlation_f: 0.7370
Epoch 8/60
48000/48000 [==============================] - 3s 72us/step - loss: 0.0354 - mean_absolute_error: 0.1493 - mean_squared_error: 0.0354 - acc: 0.4935 - pearson_correlation_f: 0.8293 - val_loss: 0.0583 - val_mean_absolute_error: 0.1911 - val_mean_squared_error: 0.0583 - val_acc: 0.4675 - val_pearson_correlation_f: 0.7348
Epoch 9/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0321 - mean_absolute_error: 0.1418 - mean_squared_error: 0.0321 - acc: 0.4945 - pearson_correlation_f: 0.8479 - val_loss: 0.0559 - val_mean_absolute_error: 0.1834 - val_mean_squared_error: 0.0559 - val_acc: 0.4655 - val_pearson_correlation_f: 0.7369
Epoch 10/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0296 - mean_absolute_error: 0.1353 - mean_squared_error: 0.0296 - acc: 0.4960 - pearson_correlation_f: 0.8627 - val_loss: 0.0496 - val_mean_absolute_error: 0.1720 - val_mean_squared_error: 0.0496 - val_acc: 0.4763 - val_pearson_correlation_f: 0.7450
Epoch 11/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0270 - mean_absolute_error: 0.1292 - mean_squared_error: 0.0270 - acc: 0.4971 - pearson_correlation_f: 0.8760 - val_loss: 0.0490 - val_mean_absolute_error: 0.1711 - val_mean_squared_error: 0.0490 - val_acc: 0.4775 - val_pearson_correlation_f: 0.7501
Epoch 12/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0252 - mean_absolute_error: 0.1246 - mean_squared_error: 0.0252 - acc: 0.4976 - pearson_correlation_f: 0.8856 - val_loss: 0.0506 - val_mean_absolute_error: 0.1744 - val_mean_squared_error: 0.0506 - val_acc: 0.4762 - val_pearson_correlation_f: 0.7447
Epoch 13/60
48000/48000 [==============================] - 3s 70us/step - loss: 0.0234 - mean_absolute_error: 0.1199 - mean_squared_error: 0.0234 - acc: 0.4981 - pearson_correlation_f: 0.8951 - val_loss: 0.0514 - val_mean_absolute_error: 0.1755 - val_mean_squared_error: 0.0514 - val_acc: 0.4765 - val_pearson_correlation_f: 0.7402
Epoch 14/60
48000/48000 [==============================] - 3s 71us/step - loss: 0.0218 - mean_absolute_error: 0.1150 - mean_squared_error: 0.0218 - acc: 0.4981 - pearson_correlation_f: 0.9024 - val_loss: 0.0577 - val_mean_absolute_error: 0.1877 - val_mean_squared_error: 0.0577 - val_acc: 0.4808 - val_pearson_correlation_f: 0.7476
6000/6000 [==============================] - 0s 70us/step
Test result:  [0.05564964871605237, 0.18559018055597942, 0.05564964871605237, 0.48483333333333334, 0.7527214360237121]
python3 main.py mutate USE FC --extra=replace
Using TensorFlow backend.
Setting:  mutate USE 30000 1 FC replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:40:23.769911: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:40:24.579925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:40:24.580455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:40:24.580473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:40:34.010018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:40:34.010058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:40:34.010067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:40:34.010988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 19s 403us/step - loss: 0.1096 - mean_absolute_error: 0.2557 - mean_squared_error: 0.1096 - acc: 0.4320 - pearson_correlation_f: 0.5921 - val_loss: 0.0416 - val_mean_absolute_error: 0.1698 - val_mean_squared_error: 0.0416 - val_acc: 0.4937 - val_pearson_correlation_f: 0.8606
Epoch 2/60
48000/48000 [==============================] - 3s 63us/step - loss: 0.0340 - mean_absolute_error: 0.1449 - mean_squared_error: 0.0340 - acc: 0.4970 - pearson_correlation_f: 0.8692 - val_loss: 0.0309 - val_mean_absolute_error: 0.1421 - val_mean_squared_error: 0.0309 - val_acc: 0.4972 - val_pearson_correlation_f: 0.8774
Epoch 3/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0272 - mean_absolute_error: 0.1296 - mean_squared_error: 0.0272 - acc: 0.4989 - pearson_correlation_f: 0.8898 - val_loss: 0.0225 - val_mean_absolute_error: 0.1162 - val_mean_squared_error: 0.0225 - val_acc: 0.4988 - val_pearson_correlation_f: 0.8870
Epoch 4/60
48000/48000 [==============================] - 3s 67us/step - loss: 0.0235 - mean_absolute_error: 0.1197 - mean_squared_error: 0.0235 - acc: 0.4992 - pearson_correlation_f: 0.9005 - val_loss: 0.0345 - val_mean_absolute_error: 0.1454 - val_mean_squared_error: 0.0345 - val_acc: 0.4993 - val_pearson_correlation_f: 0.8858
Epoch 5/60
48000/48000 [==============================] - 3s 68us/step - loss: 0.0213 - mean_absolute_error: 0.1138 - mean_squared_error: 0.0213 - acc: 0.4995 - pearson_correlation_f: 0.9078 - val_loss: 0.0236 - val_mean_absolute_error: 0.1215 - val_mean_squared_error: 0.0236 - val_acc: 0.4987 - val_pearson_correlation_f: 0.8892
Epoch 6/60
48000/48000 [==============================] - 3s 63us/step - loss: 0.0197 - mean_absolute_error: 0.1094 - mean_squared_error: 0.0197 - acc: 0.4997 - pearson_correlation_f: 0.9140 - val_loss: 0.0249 - val_mean_absolute_error: 0.1213 - val_mean_squared_error: 0.0249 - val_acc: 0.4995 - val_pearson_correlation_f: 0.8886
6000/6000 [==============================] - 0s 72us/step
Test result:  [0.024805260315537453, 0.12103335112333298, 0.024805260315537453, 0.49966666666666665, 0.8866013835271199]
python3 main.py mutate USE CNN --extra=add
Using TensorFlow backend.
Setting:  mutate USE 30000 1 CNN add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:42:51.341484: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:42:51.871179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:42:51.871810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:42:51.871841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:43:00.155960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:43:00.156002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:43:00.156012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:43:00.158653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 09:43:06.026808: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
48000/48000 [==============================] - 19s 393us/step - loss: 0.1134 - mean_absolute_error: 0.2529 - mean_squared_error: 0.1134 - acc: 0.4393 - pearson_correlation_f: 0.4606 - val_loss: 0.0271 - val_mean_absolute_error: 0.1250 - val_mean_squared_error: 0.0271 - val_acc: 0.4973 - val_pearson_correlation_f: 0.8675
Epoch 2/60
48000/48000 [==============================] - 5s 95us/step - loss: 0.0269 - mean_absolute_error: 0.1193 - mean_squared_error: 0.0269 - acc: 0.4988 - pearson_correlation_f: 0.8822 - val_loss: 0.0230 - val_mean_absolute_error: 0.1141 - val_mean_squared_error: 0.0230 - val_acc: 0.4985 - val_pearson_correlation_f: 0.8873
Epoch 3/60
48000/48000 [==============================] - 4s 93us/step - loss: 0.0224 - mean_absolute_error: 0.1071 - mean_squared_error: 0.0224 - acc: 0.4992 - pearson_correlation_f: 0.8997 - val_loss: 0.0201 - val_mean_absolute_error: 0.0961 - val_mean_squared_error: 0.0201 - val_acc: 0.4990 - val_pearson_correlation_f: 0.8956
Epoch 4/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.0196 - mean_absolute_error: 0.0990 - mean_squared_error: 0.0196 - acc: 0.4996 - pearson_correlation_f: 0.9125 - val_loss: 0.0201 - val_mean_absolute_error: 0.0940 - val_mean_squared_error: 0.0201 - val_acc: 0.4988 - val_pearson_correlation_f: 0.8971
Epoch 5/60
48000/48000 [==============================] - 4s 93us/step - loss: 0.0174 - mean_absolute_error: 0.0927 - mean_squared_error: 0.0174 - acc: 0.4998 - pearson_correlation_f: 0.9228 - val_loss: 0.0240 - val_mean_absolute_error: 0.1163 - val_mean_squared_error: 0.0240 - val_acc: 0.4970 - val_pearson_correlation_f: 0.8978
Epoch 6/60
48000/48000 [==============================] - 4s 93us/step - loss: 0.0154 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0154 - acc: 0.4998 - pearson_correlation_f: 0.9322 - val_loss: 0.0223 - val_mean_absolute_error: 0.1059 - val_mean_squared_error: 0.0223 - val_acc: 0.4982 - val_pearson_correlation_f: 0.8967
2018-12-10 09:43:33.086025: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
6000/6000 [==============================] - 0s 81us/step
Test result:  [0.023057585577170053, 0.10676856418450674, 0.023057585577170053, 0.499, 0.895478581905365]
python3 main.py mutate USE CNN --extra=delete
Using TensorFlow backend.
Setting:  mutate USE 30000 1 CNN delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:45:22.494458: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:45:23.007747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:45:23.008268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:45:23.008287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:45:31.390994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:45:31.391034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:45:31.391042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:45:31.395230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 09:45:37.337210: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
48000/48000 [==============================] - 19s 391us/step - loss: 0.1400 - mean_absolute_error: 0.2934 - mean_squared_error: 0.1400 - acc: 0.4327 - pearson_correlation_f: 0.3249 - val_loss: 0.0534 - val_mean_absolute_error: 0.1858 - val_mean_squared_error: 0.0534 - val_acc: 0.4813 - val_pearson_correlation_f: 0.7091
Epoch 2/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0505 - mean_absolute_error: 0.1753 - mean_squared_error: 0.0505 - acc: 0.4847 - pearson_correlation_f: 0.7436 - val_loss: 0.0442 - val_mean_absolute_error: 0.1637 - val_mean_squared_error: 0.0442 - val_acc: 0.4787 - val_pearson_correlation_f: 0.7786
Epoch 3/60
48000/48000 [==============================] - 4s 90us/step - loss: 0.0416 - mean_absolute_error: 0.1549 - mean_squared_error: 0.0416 - acc: 0.4872 - pearson_correlation_f: 0.7901 - val_loss: 0.0387 - val_mean_absolute_error: 0.1447 - val_mean_squared_error: 0.0387 - val_acc: 0.4865 - val_pearson_correlation_f: 0.7938
Epoch 4/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0368 - mean_absolute_error: 0.1435 - mean_squared_error: 0.0368 - acc: 0.4896 - pearson_correlation_f: 0.8175 - val_loss: 0.0410 - val_mean_absolute_error: 0.1532 - val_mean_squared_error: 0.0410 - val_acc: 0.4792 - val_pearson_correlation_f: 0.8061
Epoch 5/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0325 - mean_absolute_error: 0.1334 - mean_squared_error: 0.0325 - acc: 0.4923 - pearson_correlation_f: 0.8396 - val_loss: 0.0360 - val_mean_absolute_error: 0.1347 - val_mean_squared_error: 0.0360 - val_acc: 0.4890 - val_pearson_correlation_f: 0.8125
Epoch 6/60
48000/48000 [==============================] - 4s 90us/step - loss: 0.0291 - mean_absolute_error: 0.1253 - mean_squared_error: 0.0291 - acc: 0.4940 - pearson_correlation_f: 0.8587 - val_loss: 0.0356 - val_mean_absolute_error: 0.1335 - val_mean_squared_error: 0.0356 - val_acc: 0.4880 - val_pearson_correlation_f: 0.8128
Epoch 7/60
48000/48000 [==============================] - 4s 88us/step - loss: 0.0262 - mean_absolute_error: 0.1188 - mean_squared_error: 0.0262 - acc: 0.4956 - pearson_correlation_f: 0.8747 - val_loss: 0.0363 - val_mean_absolute_error: 0.1342 - val_mean_squared_error: 0.0363 - val_acc: 0.4898 - val_pearson_correlation_f: 0.8125
Epoch 8/60
48000/48000 [==============================] - 4s 87us/step - loss: 0.0238 - mean_absolute_error: 0.1130 - mean_squared_error: 0.0238 - acc: 0.4967 - pearson_correlation_f: 0.8878 - val_loss: 0.0388 - val_mean_absolute_error: 0.1423 - val_mean_squared_error: 0.0388 - val_acc: 0.4813 - val_pearson_correlation_f: 0.8120
Epoch 9/60
48000/48000 [==============================] - 4s 90us/step - loss: 0.0215 - mean_absolute_error: 0.1072 - mean_squared_error: 0.0215 - acc: 0.4975 - pearson_correlation_f: 0.9000 - val_loss: 0.0429 - val_mean_absolute_error: 0.1491 - val_mean_squared_error: 0.0429 - val_acc: 0.4747 - val_pearson_correlation_f: 0.8116
2018-12-10 09:46:15.973978: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
6000/6000 [==============================] - 1s 90us/step
Test result:  [0.044281581143538154, 0.15042232100168865, 0.044281581143538154, 0.4736666666666667, 0.7960393942197164]
python3 main.py mutate USE CNN --extra=replace
Using TensorFlow backend.
Setting:  mutate USE 30000 1 CNN replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:48:10.010503: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:48:10.566936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:48:10.567475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:48:10.567494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:48:19.648179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:48:19.648220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:48:19.648236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:48:19.651661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 09:48:26.222569: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
48000/48000 [==============================] - 20s 426us/step - loss: 0.1166 - mean_absolute_error: 0.2442 - mean_squared_error: 0.1166 - acc: 0.4381 - pearson_correlation_f: 0.5401 - val_loss: 0.0245 - val_mean_absolute_error: 0.1109 - val_mean_squared_error: 0.0245 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9016
Epoch 2/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0199 - mean_absolute_error: 0.1037 - mean_squared_error: 0.0199 - acc: 0.4993 - pearson_correlation_f: 0.9184 - val_loss: 0.0193 - val_mean_absolute_error: 0.1103 - val_mean_squared_error: 0.0193 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9207
Epoch 3/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0163 - mean_absolute_error: 0.0921 - mean_squared_error: 0.0163 - acc: 0.4994 - pearson_correlation_f: 0.9305 - val_loss: 0.0146 - val_mean_absolute_error: 0.0817 - val_mean_squared_error: 0.0146 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9284
Epoch 4/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0141 - mean_absolute_error: 0.0846 - mean_squared_error: 0.0141 - acc: 0.4998 - pearson_correlation_f: 0.9383 - val_loss: 0.0162 - val_mean_absolute_error: 0.0939 - val_mean_squared_error: 0.0162 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9279
Epoch 5/60
48000/48000 [==============================] - 4s 85us/step - loss: 0.0124 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0124 - acc: 0.4998 - pearson_correlation_f: 0.9449 - val_loss: 0.0152 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0152 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9296
Epoch 6/60
48000/48000 [==============================] - 4s 86us/step - loss: 0.0111 - mean_absolute_error: 0.0735 - mean_squared_error: 0.0111 - acc: 0.4998 - pearson_correlation_f: 0.9511 - val_loss: 0.0147 - val_mean_absolute_error: 0.0859 - val_mean_squared_error: 0.0147 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9302
2018-12-10 09:48:51.708603: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
6000/6000 [==============================] - 1s 90us/step
Test result:  [0.0149428850710392, 0.08521984783808391, 0.0149428850710392, 0.49933333333333335, 0.9295606616338095]
python3 main.py mutate USE LSTM --extra=add
Using TensorFlow backend.
Setting:  mutate USE 30000 1 LSTM add
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 09:50:46.065144: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 09:50:46.542498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 09:50:46.543039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 09:50:46.543060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 09:50:54.292457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 09:50:54.292498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 09:50:54.292507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 09:50:54.293761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 36s 756us/step - loss: 0.1405 - mean_absolute_error: 0.2847 - mean_squared_error: 0.1405 - acc: 0.3986 - pearson_correlation_f: 0.4877 - val_loss: 0.0348 - val_mean_absolute_error: 0.1386 - val_mean_squared_error: 0.0348 - val_acc: 0.4993 - val_pearson_correlation_f: 0.8221
Epoch 2/60
48000/48000 [==============================] - 23s 486us/step - loss: 0.0307 - mean_absolute_error: 0.1329 - mean_squared_error: 0.0307 - acc: 0.4993 - pearson_correlation_f: 0.8452 - val_loss: 0.0270 - val_mean_absolute_error: 0.1213 - val_mean_squared_error: 0.0270 - val_acc: 0.4997 - val_pearson_correlation_f: 0.8586
Epoch 3/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0265 - mean_absolute_error: 0.1212 - mean_squared_error: 0.0265 - acc: 0.4995 - pearson_correlation_f: 0.8676 - val_loss: 0.0254 - val_mean_absolute_error: 0.1209 - val_mean_squared_error: 0.0254 - val_acc: 0.4988 - val_pearson_correlation_f: 0.8723
Epoch 4/60
48000/48000 [==============================] - 23s 486us/step - loss: 0.0238 - mean_absolute_error: 0.1137 - mean_squared_error: 0.0238 - acc: 0.4996 - pearson_correlation_f: 0.8824 - val_loss: 0.0229 - val_mean_absolute_error: 0.1124 - val_mean_squared_error: 0.0229 - val_acc: 0.4993 - val_pearson_correlation_f: 0.8835
Epoch 5/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0220 - mean_absolute_error: 0.1073 - mean_squared_error: 0.0220 - acc: 0.4996 - pearson_correlation_f: 0.8911 - val_loss: 0.0216 - val_mean_absolute_error: 0.1036 - val_mean_squared_error: 0.0216 - val_acc: 0.4997 - val_pearson_correlation_f: 0.8912
Epoch 6/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0206 - mean_absolute_error: 0.1016 - mean_squared_error: 0.0206 - acc: 0.4994 - pearson_correlation_f: 0.8982 - val_loss: 0.0202 - val_mean_absolute_error: 0.0989 - val_mean_squared_error: 0.0202 - val_acc: 0.4992 - val_pearson_correlation_f: 0.8957
Epoch 7/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0197 - mean_absolute_error: 0.0976 - mean_squared_error: 0.0197 - acc: 0.4994 - pearson_correlation_f: 0.9024 - val_loss: 0.0206 - val_mean_absolute_error: 0.0968 - val_mean_squared_error: 0.0206 - val_acc: 0.4995 - val_pearson_correlation_f: 0.8939
Epoch 8/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0192 - mean_absolute_error: 0.0950 - mean_squared_error: 0.0192 - acc: 0.4994 - pearson_correlation_f: 0.9053 - val_loss: 0.0211 - val_mean_absolute_error: 0.0961 - val_mean_squared_error: 0.0211 - val_acc: 0.4993 - val_pearson_correlation_f: 0.8978
Epoch 9/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.0188 - mean_absolute_error: 0.0932 - mean_squared_error: 0.0188 - acc: 0.4994 - pearson_correlation_f: 0.9071 - val_loss: 0.0194 - val_mean_absolute_error: 0.0939 - val_mean_squared_error: 0.0194 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9016
Epoch 10/60
48000/48000 [==============================] - 23s 484us/step - loss: 0.0185 - mean_absolute_error: 0.0920 - mean_squared_error: 0.0185 - acc: 0.4995 - pearson_correlation_f: 0.9091 - val_loss: 0.0207 - val_mean_absolute_error: 0.0938 - val_mean_squared_error: 0.0207 - val_acc: 0.4997 - val_pearson_correlation_f: 0.8999
Epoch 11/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0182 - mean_absolute_error: 0.0910 - mean_squared_error: 0.0182 - acc: 0.4995 - pearson_correlation_f: 0.9104 - val_loss: 0.0192 - val_mean_absolute_error: 0.0900 - val_mean_squared_error: 0.0192 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9035
Epoch 12/60
48000/48000 [==============================] - 23s 486us/step - loss: 0.0179 - mean_absolute_error: 0.0896 - mean_squared_error: 0.0179 - acc: 0.4995 - pearson_correlation_f: 0.9118 - val_loss: 0.0202 - val_mean_absolute_error: 0.1018 - val_mean_squared_error: 0.0202 - val_acc: 0.4985 - val_pearson_correlation_f: 0.9044
Epoch 13/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0177 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0177 - acc: 0.4996 - pearson_correlation_f: 0.9133 - val_loss: 0.0186 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.0186 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9050
Epoch 14/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0174 - mean_absolute_error: 0.0877 - mean_squared_error: 0.0174 - acc: 0.4996 - pearson_correlation_f: 0.9143 - val_loss: 0.0183 - val_mean_absolute_error: 0.0909 - val_mean_squared_error: 0.0183 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9060
Epoch 15/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0172 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0172 - acc: 0.4995 - pearson_correlation_f: 0.9151 - val_loss: 0.0182 - val_mean_absolute_error: 0.0875 - val_mean_squared_error: 0.0182 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9065
Epoch 16/60
48000/48000 [==============================] - 23s 487us/step - loss: 0.0170 - mean_absolute_error: 0.0861 - mean_squared_error: 0.0170 - acc: 0.4996 - pearson_correlation_f: 0.9159 - val_loss: 0.0181 - val_mean_absolute_error: 0.0882 - val_mean_squared_error: 0.0181 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9071
Epoch 17/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.0169 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0169 - acc: 0.4996 - pearson_correlation_f: 0.9169 - val_loss: 0.0201 - val_mean_absolute_error: 0.1014 - val_mean_squared_error: 0.0201 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9049
Epoch 18/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0167 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0167 - acc: 0.4996 - pearson_correlation_f: 0.9180 - val_loss: 0.0181 - val_mean_absolute_error: 0.0889 - val_mean_squared_error: 0.0181 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9073
Epoch 19/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0165 - mean_absolute_error: 0.0845 - mean_squared_error: 0.0165 - acc: 0.4997 - pearson_correlation_f: 0.9186 - val_loss: 0.0184 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0184 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9060
6000/6000 [==============================] - 4s 625us/step
Test result:  [0.01758243504414956, 0.08356460289160411, 0.01758243504414956, 0.49966666666666665, 0.9121833866437277]
python3 main.py mutate USE LSTM --extra=delete
Using TensorFlow backend.
Setting:  mutate USE 30000 1 LSTM delete
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 10:00:11.284013: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:00:11.741108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:00:11.741648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:00:11.741667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:00:20.620083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:00:20.620125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:00:20.620140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:00:20.621225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 39s 803us/step - loss: 0.1571 - mean_absolute_error: 0.3188 - mean_squared_error: 0.1571 - acc: 0.3998 - pearson_correlation_f: 0.3478 - val_loss: 0.0652 - val_mean_absolute_error: 0.2162 - val_mean_squared_error: 0.0652 - val_acc: 0.4860 - val_pearson_correlation_f: 0.6169
Epoch 2/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0562 - mean_absolute_error: 0.1944 - mean_squared_error: 0.0562 - acc: 0.4819 - pearson_correlation_f: 0.6851 - val_loss: 0.0504 - val_mean_absolute_error: 0.1790 - val_mean_squared_error: 0.0504 - val_acc: 0.4780 - val_pearson_correlation_f: 0.7195
Epoch 3/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0481 - mean_absolute_error: 0.1732 - mean_squared_error: 0.0481 - acc: 0.4811 - pearson_correlation_f: 0.7365 - val_loss: 0.0477 - val_mean_absolute_error: 0.1694 - val_mean_squared_error: 0.0477 - val_acc: 0.4870 - val_pearson_correlation_f: 0.7492
Epoch 4/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0449 - mean_absolute_error: 0.1644 - mean_squared_error: 0.0449 - acc: 0.4820 - pearson_correlation_f: 0.7581 - val_loss: 0.0438 - val_mean_absolute_error: 0.1604 - val_mean_squared_error: 0.0438 - val_acc: 0.4822 - val_pearson_correlation_f: 0.7622
Epoch 5/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0428 - mean_absolute_error: 0.1591 - mean_squared_error: 0.0428 - acc: 0.4831 - pearson_correlation_f: 0.7696 - val_loss: 0.0433 - val_mean_absolute_error: 0.1615 - val_mean_squared_error: 0.0433 - val_acc: 0.4805 - val_pearson_correlation_f: 0.7697
Epoch 6/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0412 - mean_absolute_error: 0.1554 - mean_squared_error: 0.0412 - acc: 0.4844 - pearson_correlation_f: 0.7802 - val_loss: 0.0408 - val_mean_absolute_error: 0.1542 - val_mean_squared_error: 0.0408 - val_acc: 0.4837 - val_pearson_correlation_f: 0.7809
Epoch 7/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0396 - mean_absolute_error: 0.1513 - mean_squared_error: 0.0396 - acc: 0.4853 - pearson_correlation_f: 0.7897 - val_loss: 0.0433 - val_mean_absolute_error: 0.1569 - val_mean_squared_error: 0.0433 - val_acc: 0.4920 - val_pearson_correlation_f: 0.7892
Epoch 8/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0382 - mean_absolute_error: 0.1480 - mean_squared_error: 0.0382 - acc: 0.4864 - pearson_correlation_f: 0.7977 - val_loss: 0.0392 - val_mean_absolute_error: 0.1498 - val_mean_squared_error: 0.0392 - val_acc: 0.4895 - val_pearson_correlation_f: 0.7970
Epoch 9/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0370 - mean_absolute_error: 0.1449 - mean_squared_error: 0.0370 - acc: 0.4874 - pearson_correlation_f: 0.8057 - val_loss: 0.0368 - val_mean_absolute_error: 0.1432 - val_mean_squared_error: 0.0368 - val_acc: 0.4868 - val_pearson_correlation_f: 0.8048
Epoch 10/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0357 - mean_absolute_error: 0.1420 - mean_squared_error: 0.0357 - acc: 0.4881 - pearson_correlation_f: 0.8127 - val_loss: 0.0362 - val_mean_absolute_error: 0.1426 - val_mean_squared_error: 0.0362 - val_acc: 0.4862 - val_pearson_correlation_f: 0.8083
Epoch 11/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0348 - mean_absolute_error: 0.1392 - mean_squared_error: 0.0348 - acc: 0.4885 - pearson_correlation_f: 0.8172 - val_loss: 0.0356 - val_mean_absolute_error: 0.1397 - val_mean_squared_error: 0.0356 - val_acc: 0.4892 - val_pearson_correlation_f: 0.8128
Epoch 12/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0340 - mean_absolute_error: 0.1371 - mean_squared_error: 0.0340 - acc: 0.4889 - pearson_correlation_f: 0.8228 - val_loss: 0.0364 - val_mean_absolute_error: 0.1409 - val_mean_squared_error: 0.0364 - val_acc: 0.4818 - val_pearson_correlation_f: 0.8120
Epoch 13/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0333 - mean_absolute_error: 0.1355 - mean_squared_error: 0.0333 - acc: 0.4893 - pearson_correlation_f: 0.8259 - val_loss: 0.0356 - val_mean_absolute_error: 0.1386 - val_mean_squared_error: 0.0356 - val_acc: 0.4927 - val_pearson_correlation_f: 0.8160
Epoch 14/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0324 - mean_absolute_error: 0.1334 - mean_squared_error: 0.0324 - acc: 0.4903 - pearson_correlation_f: 0.8304 - val_loss: 0.0344 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0344 - val_acc: 0.4882 - val_pearson_correlation_f: 0.8184
Epoch 15/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0318 - mean_absolute_error: 0.1318 - mean_squared_error: 0.0318 - acc: 0.4897 - pearson_correlation_f: 0.8347 - val_loss: 0.0356 - val_mean_absolute_error: 0.1396 - val_mean_squared_error: 0.0356 - val_acc: 0.4837 - val_pearson_correlation_f: 0.8178
Epoch 16/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0311 - mean_absolute_error: 0.1302 - mean_squared_error: 0.0311 - acc: 0.4906 - pearson_correlation_f: 0.8387 - val_loss: 0.0348 - val_mean_absolute_error: 0.1363 - val_mean_squared_error: 0.0348 - val_acc: 0.4835 - val_pearson_correlation_f: 0.8220
Epoch 17/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0304 - mean_absolute_error: 0.1282 - mean_squared_error: 0.0304 - acc: 0.4910 - pearson_correlation_f: 0.8425 - val_loss: 0.0333 - val_mean_absolute_error: 0.1327 - val_mean_squared_error: 0.0333 - val_acc: 0.4877 - val_pearson_correlation_f: 0.8253
Epoch 18/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0298 - mean_absolute_error: 0.1265 - mean_squared_error: 0.0298 - acc: 0.4912 - pearson_correlation_f: 0.8470 - val_loss: 0.0330 - val_mean_absolute_error: 0.1310 - val_mean_squared_error: 0.0330 - val_acc: 0.4872 - val_pearson_correlation_f: 0.8282
Epoch 19/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0291 - mean_absolute_error: 0.1246 - mean_squared_error: 0.0291 - acc: 0.4917 - pearson_correlation_f: 0.8500 - val_loss: 0.0320 - val_mean_absolute_error: 0.1311 - val_mean_squared_error: 0.0320 - val_acc: 0.4908 - val_pearson_correlation_f: 0.8327
Epoch 20/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0283 - mean_absolute_error: 0.1228 - mean_squared_error: 0.0283 - acc: 0.4922 - pearson_correlation_f: 0.8540 - val_loss: 0.0321 - val_mean_absolute_error: 0.1311 - val_mean_squared_error: 0.0321 - val_acc: 0.4893 - val_pearson_correlation_f: 0.8340
Epoch 21/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0277 - mean_absolute_error: 0.1211 - mean_squared_error: 0.0277 - acc: 0.4927 - pearson_correlation_f: 0.8577 - val_loss: 0.0338 - val_mean_absolute_error: 0.1329 - val_mean_squared_error: 0.0338 - val_acc: 0.4832 - val_pearson_correlation_f: 0.8316
Epoch 22/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0273 - mean_absolute_error: 0.1197 - mean_squared_error: 0.0273 - acc: 0.4925 - pearson_correlation_f: 0.8605 - val_loss: 0.0311 - val_mean_absolute_error: 0.1260 - val_mean_squared_error: 0.0311 - val_acc: 0.4907 - val_pearson_correlation_f: 0.8383
Epoch 23/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0266 - mean_absolute_error: 0.1177 - mean_squared_error: 0.0266 - acc: 0.4926 - pearson_correlation_f: 0.8635 - val_loss: 0.0325 - val_mean_absolute_error: 0.1269 - val_mean_squared_error: 0.0325 - val_acc: 0.4920 - val_pearson_correlation_f: 0.8364
Epoch 24/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0261 - mean_absolute_error: 0.1163 - mean_squared_error: 0.0261 - acc: 0.4931 - pearson_correlation_f: 0.8667 - val_loss: 0.0311 - val_mean_absolute_error: 0.1256 - val_mean_squared_error: 0.0311 - val_acc: 0.4892 - val_pearson_correlation_f: 0.8372
Epoch 25/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0257 - mean_absolute_error: 0.1150 - mean_squared_error: 0.0257 - acc: 0.4933 - pearson_correlation_f: 0.8689 - val_loss: 0.0305 - val_mean_absolute_error: 0.1229 - val_mean_squared_error: 0.0305 - val_acc: 0.4905 - val_pearson_correlation_f: 0.8425
Epoch 26/60
48000/48000 [==============================] - 23s 489us/step - loss: 0.0251 - mean_absolute_error: 0.1133 - mean_squared_error: 0.0251 - acc: 0.4935 - pearson_correlation_f: 0.8714 - val_loss: 0.0298 - val_mean_absolute_error: 0.1215 - val_mean_squared_error: 0.0298 - val_acc: 0.4892 - val_pearson_correlation_f: 0.8451
Epoch 27/60
48000/48000 [==============================] - 24s 494us/step - loss: 0.0248 - mean_absolute_error: 0.1123 - mean_squared_error: 0.0248 - acc: 0.4936 - pearson_correlation_f: 0.8737 - val_loss: 0.0312 - val_mean_absolute_error: 0.1243 - val_mean_squared_error: 0.0312 - val_acc: 0.4865 - val_pearson_correlation_f: 0.8424
Epoch 28/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0244 - mean_absolute_error: 0.1110 - mean_squared_error: 0.0244 - acc: 0.4938 - pearson_correlation_f: 0.8760 - val_loss: 0.0302 - val_mean_absolute_error: 0.1209 - val_mean_squared_error: 0.0302 - val_acc: 0.4923 - val_pearson_correlation_f: 0.8455
Epoch 29/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0239 - mean_absolute_error: 0.1098 - mean_squared_error: 0.0239 - acc: 0.4938 - pearson_correlation_f: 0.8782 - val_loss: 0.0295 - val_mean_absolute_error: 0.1196 - val_mean_squared_error: 0.0295 - val_acc: 0.4898 - val_pearson_correlation_f: 0.8473
Epoch 30/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0235 - mean_absolute_error: 0.1084 - mean_squared_error: 0.0235 - acc: 0.4942 - pearson_correlation_f: 0.8799 - val_loss: 0.0318 - val_mean_absolute_error: 0.1248 - val_mean_squared_error: 0.0318 - val_acc: 0.4842 - val_pearson_correlation_f: 0.8455
Epoch 31/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0232 - mean_absolute_error: 0.1074 - mean_squared_error: 0.0232 - acc: 0.4944 - pearson_correlation_f: 0.8821 - val_loss: 0.0295 - val_mean_absolute_error: 0.1190 - val_mean_squared_error: 0.0295 - val_acc: 0.4885 - val_pearson_correlation_f: 0.8484
Epoch 32/60
48000/48000 [==============================] - 24s 490us/step - loss: 0.0228 - mean_absolute_error: 0.1063 - mean_squared_error: 0.0228 - acc: 0.4947 - pearson_correlation_f: 0.8844 - val_loss: 0.0294 - val_mean_absolute_error: 0.1184 - val_mean_squared_error: 0.0294 - val_acc: 0.4898 - val_pearson_correlation_f: 0.8482
Epoch 33/60
48000/48000 [==============================] - 23s 488us/step - loss: 0.0226 - mean_absolute_error: 0.1056 - mean_squared_error: 0.0226 - acc: 0.4947 - pearson_correlation_f: 0.8854 - val_loss: 0.0293 - val_mean_absolute_error: 0.1171 - val_mean_squared_error: 0.0293 - val_acc: 0.4892 - val_pearson_correlation_f: 0.8493
Epoch 34/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0221 - mean_absolute_error: 0.1044 - mean_squared_error: 0.0221 - acc: 0.4947 - pearson_correlation_f: 0.8874 - val_loss: 0.0290 - val_mean_absolute_error: 0.1165 - val_mean_squared_error: 0.0290 - val_acc: 0.4890 - val_pearson_correlation_f: 0.8507
Epoch 35/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0219 - mean_absolute_error: 0.1037 - mean_squared_error: 0.0219 - acc: 0.4951 - pearson_correlation_f: 0.8894 - val_loss: 0.0297 - val_mean_absolute_error: 0.1169 - val_mean_squared_error: 0.0297 - val_acc: 0.4877 - val_pearson_correlation_f: 0.8467
Epoch 36/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0215 - mean_absolute_error: 0.1028 - mean_squared_error: 0.0215 - acc: 0.4953 - pearson_correlation_f: 0.8910 - val_loss: 0.0298 - val_mean_absolute_error: 0.1152 - val_mean_squared_error: 0.0298 - val_acc: 0.4887 - val_pearson_correlation_f: 0.8488
Epoch 37/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0213 - mean_absolute_error: 0.1019 - mean_squared_error: 0.0213 - acc: 0.4954 - pearson_correlation_f: 0.8924 - val_loss: 0.0287 - val_mean_absolute_error: 0.1147 - val_mean_squared_error: 0.0287 - val_acc: 0.4890 - val_pearson_correlation_f: 0.8519
Epoch 38/60
48000/48000 [==============================] - 24s 492us/step - loss: 0.0209 - mean_absolute_error: 0.1013 - mean_squared_error: 0.0209 - acc: 0.4954 - pearson_correlation_f: 0.8939 - val_loss: 0.0297 - val_mean_absolute_error: 0.1169 - val_mean_squared_error: 0.0297 - val_acc: 0.4857 - val_pearson_correlation_f: 0.8501
Epoch 39/60
48000/48000 [==============================] - 24s 491us/step - loss: 0.0206 - mean_absolute_error: 0.1003 - mean_squared_error: 0.0206 - acc: 0.4959 - pearson_correlation_f: 0.8953 - val_loss: 0.0297 - val_mean_absolute_error: 0.1182 - val_mean_squared_error: 0.0297 - val_acc: 0.4878 - val_pearson_correlation_f: 0.8520
Epoch 40/60
48000/48000 [==============================] - 24s 493us/step - loss: 0.0204 - mean_absolute_error: 0.0995 - mean_squared_error: 0.0204 - acc: 0.4958 - pearson_correlation_f: 0.8971 - val_loss: 0.0291 - val_mean_absolute_error: 0.1158 - val_mean_squared_error: 0.0291 - val_acc: 0.4887 - val_pearson_correlation_f: 0.8512
6000/6000 [==============================] - 4s 634us/step
Test result:  [0.02939310392489036, 0.11606752542654673, 0.02939310392489036, 0.48783333333333334, 0.8508128854433695]
python3 main.py mutate USE LSTM --extra=replace
Using TensorFlow backend.
Setting:  mutate USE 30000 1 LSTM replace
loading data ..
loading pickle ..
retrieving article ..
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (48000, 50, 512) (48000,)
val:  (6000, 50, 512) (6000,)
test:  (6000, 50, 512) (6000,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 48000 samples, validate on 6000 samples
Epoch 1/60
2018-12-10 10:18:01.339828: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:18:01.859311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:18:01.859925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:18:01.859953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:18:10.946474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:18:10.946515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:18:10.946523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:18:10.947771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
48000/48000 [==============================] - 38s 794us/step - loss: 0.1319 - mean_absolute_error: 0.2681 - mean_squared_error: 0.1319 - acc: 0.3995 - pearson_correlation_f: 0.5652 - val_loss: 0.0266 - val_mean_absolute_error: 0.1261 - val_mean_squared_error: 0.0266 - val_acc: 0.4995 - val_pearson_correlation_f: 0.8674
Epoch 2/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0225 - mean_absolute_error: 0.1138 - mean_squared_error: 0.0225 - acc: 0.4996 - pearson_correlation_f: 0.8898 - val_loss: 0.0208 - val_mean_absolute_error: 0.1065 - val_mean_squared_error: 0.0208 - val_acc: 0.4998 - val_pearson_correlation_f: 0.8974
Epoch 3/60
48000/48000 [==============================] - 23s 483us/step - loss: 0.0187 - mean_absolute_error: 0.1022 - mean_squared_error: 0.0187 - acc: 0.4998 - pearson_correlation_f: 0.9089 - val_loss: 0.0180 - val_mean_absolute_error: 0.0978 - val_mean_squared_error: 0.0180 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9114
Epoch 4/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0166 - mean_absolute_error: 0.0944 - mean_squared_error: 0.0166 - acc: 0.4998 - pearson_correlation_f: 0.9201 - val_loss: 0.0161 - val_mean_absolute_error: 0.0911 - val_mean_squared_error: 0.0161 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9206
Epoch 5/60
48000/48000 [==============================] - 23s 478us/step - loss: 0.0151 - mean_absolute_error: 0.0885 - mean_squared_error: 0.0151 - acc: 0.4997 - pearson_correlation_f: 0.9277 - val_loss: 0.0158 - val_mean_absolute_error: 0.0912 - val_mean_squared_error: 0.0158 - val_acc: 0.4995 - val_pearson_correlation_f: 0.9250
Epoch 6/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0143 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0143 - acc: 0.4996 - pearson_correlation_f: 0.9312 - val_loss: 0.0152 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0152 - val_acc: 0.4993 - val_pearson_correlation_f: 0.9268
Epoch 7/60
48000/48000 [==============================] - 23s 480us/step - loss: 0.0139 - mean_absolute_error: 0.0828 - mean_squared_error: 0.0139 - acc: 0.4996 - pearson_correlation_f: 0.9334 - val_loss: 0.0159 - val_mean_absolute_error: 0.0909 - val_mean_squared_error: 0.0159 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9276
Epoch 8/60
48000/48000 [==============================] - 23s 479us/step - loss: 0.0135 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0135 - acc: 0.4997 - pearson_correlation_f: 0.9350 - val_loss: 0.0143 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0143 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9305
Epoch 9/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0131 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0131 - acc: 0.4996 - pearson_correlation_f: 0.9366 - val_loss: 0.0145 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0145 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9318
Epoch 10/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0128 - mean_absolute_error: 0.0778 - mean_squared_error: 0.0128 - acc: 0.4996 - pearson_correlation_f: 0.9379 - val_loss: 0.0145 - val_mean_absolute_error: 0.0788 - val_mean_squared_error: 0.0145 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9325
Epoch 11/60
48000/48000 [==============================] - 23s 480us/step - loss: 0.0126 - mean_absolute_error: 0.0767 - mean_squared_error: 0.0126 - acc: 0.4997 - pearson_correlation_f: 0.9392 - val_loss: 0.0136 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0136 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9334
Epoch 12/60
48000/48000 [==============================] - 23s 480us/step - loss: 0.0124 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0124 - acc: 0.4997 - pearson_correlation_f: 0.9405 - val_loss: 0.0138 - val_mean_absolute_error: 0.0818 - val_mean_squared_error: 0.0138 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9337
Epoch 13/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0122 - mean_absolute_error: 0.0748 - mean_squared_error: 0.0122 - acc: 0.4997 - pearson_correlation_f: 0.9413 - val_loss: 0.0135 - val_mean_absolute_error: 0.0768 - val_mean_squared_error: 0.0135 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9348
Epoch 14/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0121 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0121 - acc: 0.4996 - pearson_correlation_f: 0.9418 - val_loss: 0.0139 - val_mean_absolute_error: 0.0783 - val_mean_squared_error: 0.0139 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9349
Epoch 15/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0118 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0118 - acc: 0.4997 - pearson_correlation_f: 0.9428 - val_loss: 0.0133 - val_mean_absolute_error: 0.0759 - val_mean_squared_error: 0.0133 - val_acc: 0.4995 - val_pearson_correlation_f: 0.9353
Epoch 16/60
48000/48000 [==============================] - 23s 480us/step - loss: 0.0117 - mean_absolute_error: 0.0726 - mean_squared_error: 0.0117 - acc: 0.4998 - pearson_correlation_f: 0.9436 - val_loss: 0.0132 - val_mean_absolute_error: 0.0763 - val_mean_squared_error: 0.0132 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9359
Epoch 17/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0116 - mean_absolute_error: 0.0719 - mean_squared_error: 0.0116 - acc: 0.4997 - pearson_correlation_f: 0.9443 - val_loss: 0.0137 - val_mean_absolute_error: 0.0794 - val_mean_squared_error: 0.0137 - val_acc: 0.4992 - val_pearson_correlation_f: 0.9362
Epoch 18/60
48000/48000 [==============================] - 23s 481us/step - loss: 0.0114 - mean_absolute_error: 0.0712 - mean_squared_error: 0.0114 - acc: 0.4997 - pearson_correlation_f: 0.9445 - val_loss: 0.0130 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0130 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9366
Epoch 19/60
48000/48000 [==============================] - 23s 480us/step - loss: 0.0113 - mean_absolute_error: 0.0707 - mean_squared_error: 0.0113 - acc: 0.4997 - pearson_correlation_f: 0.9454 - val_loss: 0.0133 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0133 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9367
Epoch 20/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0112 - mean_absolute_error: 0.0701 - mean_squared_error: 0.0112 - acc: 0.4998 - pearson_correlation_f: 0.9460 - val_loss: 0.0130 - val_mean_absolute_error: 0.0741 - val_mean_squared_error: 0.0130 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9372
Epoch 21/60
48000/48000 [==============================] - 23s 482us/step - loss: 0.0110 - mean_absolute_error: 0.0698 - mean_squared_error: 0.0110 - acc: 0.4998 - pearson_correlation_f: 0.9467 - val_loss: 0.0133 - val_mean_absolute_error: 0.0741 - val_mean_squared_error: 0.0133 - val_acc: 0.4995 - val_pearson_correlation_f: 0.9368
6000/6000 [==============================] - 4s 608us/step
Test result:  [0.012850434529284636, 0.07282997406522433, 0.012850434529284636, 0.49933333333333335, 0.9373453879356384]
python3 main.py mutate USE-Large FC --extra=add
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 FC add
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29802 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47684, 50, 512) (47684,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47684 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:28:05.495605: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:28:05.999843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:28:06.000374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:28:06.000393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:28:14.327728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:28:14.327766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:28:14.327775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:28:14.328892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47684/47684 [==============================] - 17s 353us/step - loss: 0.1106 - mean_absolute_error: 0.2514 - mean_squared_error: 0.1106 - acc: 0.4293 - pearson_correlation_f: 0.6123 - val_loss: 0.0231 - val_mean_absolute_error: 0.1165 - val_mean_squared_error: 0.0231 - val_acc: 0.5000 - val_pearson_correlation_f: 0.8819
Epoch 2/60
47684/47684 [==============================] - 3s 63us/step - loss: 0.0276 - mean_absolute_error: 0.1314 - mean_squared_error: 0.0276 - acc: 0.4992 - pearson_correlation_f: 0.8968 - val_loss: 0.0317 - val_mean_absolute_error: 0.1409 - val_mean_squared_error: 0.0317 - val_acc: 0.4998 - val_pearson_correlation_f: 0.8928
Epoch 3/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0217 - mean_absolute_error: 0.1157 - mean_squared_error: 0.0217 - acc: 0.4998 - pearson_correlation_f: 0.9153 - val_loss: 0.0200 - val_mean_absolute_error: 0.1082 - val_mean_squared_error: 0.0200 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9023
Epoch 4/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0185 - mean_absolute_error: 0.1061 - mean_squared_error: 0.0185 - acc: 0.5000 - pearson_correlation_f: 0.9255 - val_loss: 0.0200 - val_mean_absolute_error: 0.1109 - val_mean_squared_error: 0.0200 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9061
Epoch 5/60
47684/47684 [==============================] - 3s 61us/step - loss: 0.0163 - mean_absolute_error: 0.0990 - mean_squared_error: 0.0163 - acc: 0.5000 - pearson_correlation_f: 0.9332 - val_loss: 0.0189 - val_mean_absolute_error: 0.1059 - val_mean_squared_error: 0.0189 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9068
Epoch 6/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0148 - mean_absolute_error: 0.0943 - mean_squared_error: 0.0148 - acc: 0.5000 - pearson_correlation_f: 0.9382 - val_loss: 0.0204 - val_mean_absolute_error: 0.1098 - val_mean_squared_error: 0.0204 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9070
Epoch 7/60
47684/47684 [==============================] - 3s 61us/step - loss: 0.0136 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0136 - acc: 0.4999 - pearson_correlation_f: 0.9433 - val_loss: 0.0228 - val_mean_absolute_error: 0.1182 - val_mean_squared_error: 0.0228 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9077
Epoch 8/60
47684/47684 [==============================] - 3s 61us/step - loss: 0.0127 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0127 - acc: 0.5000 - pearson_correlation_f: 0.9474 - val_loss: 0.0202 - val_mean_absolute_error: 0.1119 - val_mean_squared_error: 0.0202 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9102
5960/5960 [==============================] - 0s 67us/step
Test result:  [0.019559712110449805, 0.11126104856297474, 0.019559712110449805, 0.5, 0.9151001718220295]
python3 main.py mutate USE-Large FC --extra=delete
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 FC delete
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29801 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47682, 50, 512) (47682,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47682 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:30:35.176424: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:30:35.670799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:30:35.671423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:30:35.671448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:30:43.988431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:30:43.988473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:30:43.988489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:30:43.989374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47682/47682 [==============================] - 17s 363us/step - loss: 0.1279 - mean_absolute_error: 0.2837 - mean_squared_error: 0.1279 - acc: 0.4188 - pearson_correlation_f: 0.4795 - val_loss: 0.0756 - val_mean_absolute_error: 0.2287 - val_mean_squared_error: 0.0756 - val_acc: 0.4550 - val_pearson_correlation_f: 0.7337
Epoch 2/60
47682/47682 [==============================] - 3s 62us/step - loss: 0.0510 - mean_absolute_error: 0.1807 - mean_squared_error: 0.0510 - acc: 0.4896 - pearson_correlation_f: 0.7687 - val_loss: 0.0380 - val_mean_absolute_error: 0.1586 - val_mean_squared_error: 0.0380 - val_acc: 0.4945 - val_pearson_correlation_f: 0.8069
Epoch 3/60
47682/47682 [==============================] - 3s 63us/step - loss: 0.0397 - mean_absolute_error: 0.1581 - mean_squared_error: 0.0397 - acc: 0.4939 - pearson_correlation_f: 0.8241 - val_loss: 0.0331 - val_mean_absolute_error: 0.1457 - val_mean_squared_error: 0.0331 - val_acc: 0.4948 - val_pearson_correlation_f: 0.8254
Epoch 4/60
47682/47682 [==============================] - 3s 64us/step - loss: 0.0337 - mean_absolute_error: 0.1445 - mean_squared_error: 0.0337 - acc: 0.4957 - pearson_correlation_f: 0.8523 - val_loss: 0.0357 - val_mean_absolute_error: 0.1522 - val_mean_squared_error: 0.0357 - val_acc: 0.4940 - val_pearson_correlation_f: 0.8391
Epoch 5/60
47682/47682 [==============================] - 3s 71us/step - loss: 0.0295 - mean_absolute_error: 0.1344 - mean_squared_error: 0.0295 - acc: 0.4972 - pearson_correlation_f: 0.8716 - val_loss: 0.0459 - val_mean_absolute_error: 0.1735 - val_mean_squared_error: 0.0459 - val_acc: 0.4871 - val_pearson_correlation_f: 0.8406
Epoch 6/60
47682/47682 [==============================] - 3s 62us/step - loss: 0.0264 - mean_absolute_error: 0.1268 - mean_squared_error: 0.0264 - acc: 0.4975 - pearson_correlation_f: 0.8854 - val_loss: 0.0316 - val_mean_absolute_error: 0.1361 - val_mean_squared_error: 0.0316 - val_acc: 0.4966 - val_pearson_correlation_f: 0.8447
Epoch 7/60
47682/47682 [==============================] - 3s 70us/step - loss: 0.0242 - mean_absolute_error: 0.1211 - mean_squared_error: 0.0242 - acc: 0.4979 - pearson_correlation_f: 0.8952 - val_loss: 0.0327 - val_mean_absolute_error: 0.1388 - val_mean_squared_error: 0.0327 - val_acc: 0.4965 - val_pearson_correlation_f: 0.8536
Epoch 8/60
47682/47682 [==============================] - 3s 62us/step - loss: 0.0222 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0222 - acc: 0.4983 - pearson_correlation_f: 0.9045 - val_loss: 0.0279 - val_mean_absolute_error: 0.1299 - val_mean_squared_error: 0.0279 - val_acc: 0.4951 - val_pearson_correlation_f: 0.8553
Epoch 9/60
47682/47682 [==============================] - 3s 72us/step - loss: 0.0209 - mean_absolute_error: 0.1122 - mean_squared_error: 0.0209 - acc: 0.4983 - pearson_correlation_f: 0.9109 - val_loss: 0.0295 - val_mean_absolute_error: 0.1324 - val_mean_squared_error: 0.0295 - val_acc: 0.4958 - val_pearson_correlation_f: 0.8535
Epoch 10/60
47682/47682 [==============================] - 3s 69us/step - loss: 0.0192 - mean_absolute_error: 0.1074 - mean_squared_error: 0.0192 - acc: 0.4987 - pearson_correlation_f: 0.9170 - val_loss: 0.0325 - val_mean_absolute_error: 0.1417 - val_mean_squared_error: 0.0325 - val_acc: 0.4930 - val_pearson_correlation_f: 0.8534
Epoch 11/60
47682/47682 [==============================] - 3s 66us/step - loss: 0.0183 - mean_absolute_error: 0.1045 - mean_squared_error: 0.0183 - acc: 0.4990 - pearson_correlation_f: 0.9216 - val_loss: 0.0347 - val_mean_absolute_error: 0.1469 - val_mean_squared_error: 0.0347 - val_acc: 0.4909 - val_pearson_correlation_f: 0.8533
5960/5960 [==============================] - 0s 77us/step
Test result:  [0.03452743546124673, 0.14627798113646923, 0.03452743546124673, 0.49228187919463084, 0.8560639327004452]
python3 main.py mutate USE-Large FC --extra=replace
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 FC replace
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29802 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47684, 50, 512) (47684,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25600)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3276928   
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 3,277,057
Trainable params: 3,277,057
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47684 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:33:14.807590: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:33:15.325744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:33:15.326259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:33:15.326278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:33:23.845691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:33:23.845723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:33:23.845730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:33:23.846608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47684/47684 [==============================] - 17s 367us/step - loss: 0.1078 - mean_absolute_error: 0.2433 - mean_squared_error: 0.1078 - acc: 0.4300 - pearson_correlation_f: 0.6721 - val_loss: 0.0178 - val_mean_absolute_error: 0.1030 - val_mean_squared_error: 0.0178 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9159
Epoch 2/60
47684/47684 [==============================] - 3s 64us/step - loss: 0.0212 - mean_absolute_error: 0.1145 - mean_squared_error: 0.0212 - acc: 0.4997 - pearson_correlation_f: 0.9242 - val_loss: 0.0239 - val_mean_absolute_error: 0.1255 - val_mean_squared_error: 0.0239 - val_acc: 0.4995 - val_pearson_correlation_f: 0.9128
Epoch 3/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0162 - mean_absolute_error: 0.0998 - mean_squared_error: 0.0162 - acc: 0.4999 - pearson_correlation_f: 0.9387 - val_loss: 0.0136 - val_mean_absolute_error: 0.0892 - val_mean_squared_error: 0.0136 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9373
Epoch 4/60
47684/47684 [==============================] - 3s 61us/step - loss: 0.0136 - mean_absolute_error: 0.0910 - mean_squared_error: 0.0136 - acc: 0.5000 - pearson_correlation_f: 0.9463 - val_loss: 0.0209 - val_mean_absolute_error: 0.1187 - val_mean_squared_error: 0.0209 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9333
Epoch 5/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0122 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0122 - acc: 0.5000 - pearson_correlation_f: 0.9512 - val_loss: 0.0142 - val_mean_absolute_error: 0.0934 - val_mean_squared_error: 0.0142 - val_acc: 0.4997 - val_pearson_correlation_f: 0.9400
Epoch 6/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0110 - mean_absolute_error: 0.0809 - mean_squared_error: 0.0110 - acc: 0.5000 - pearson_correlation_f: 0.9554 - val_loss: 0.0130 - val_mean_absolute_error: 0.0868 - val_mean_squared_error: 0.0130 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9395
Epoch 7/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0100 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0100 - acc: 0.5000 - pearson_correlation_f: 0.9592 - val_loss: 0.0125 - val_mean_absolute_error: 0.0846 - val_mean_squared_error: 0.0125 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9420
Epoch 8/60
47684/47684 [==============================] - 3s 62us/step - loss: 0.0092 - mean_absolute_error: 0.0739 - mean_squared_error: 0.0092 - acc: 0.5000 - pearson_correlation_f: 0.9628 - val_loss: 0.0128 - val_mean_absolute_error: 0.0863 - val_mean_squared_error: 0.0128 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9387
Epoch 9/60
47684/47684 [==============================] - 3s 68us/step - loss: 0.0085 - mean_absolute_error: 0.0708 - mean_squared_error: 0.0085 - acc: 0.5000 - pearson_correlation_f: 0.9657 - val_loss: 0.0139 - val_mean_absolute_error: 0.0901 - val_mean_squared_error: 0.0139 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9395
Epoch 10/60
47684/47684 [==============================] - 3s 61us/step - loss: 0.0080 - mean_absolute_error: 0.0685 - mean_squared_error: 0.0080 - acc: 0.5000 - pearson_correlation_f: 0.9682 - val_loss: 0.0134 - val_mean_absolute_error: 0.0881 - val_mean_squared_error: 0.0134 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9403
5960/5960 [==============================] - 0s 73us/step
Test result:  [0.013480195953141923, 0.08992541289369532, 0.013480195953141923, 0.5, 0.9418460637130993]
python3 main.py mutate USE-Large CNN --extra=add
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 CNN add
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29800 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47680, 50, 512) (47680,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47680 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:35:51.404140: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:35:51.950618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:35:51.951154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:35:51.951174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:36:00.370946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:36:00.370980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:36:00.370989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:36:00.374487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 10:36:06.471793: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
47232/47680 [============================>.] - ETA: 0s - loss: 0.0976 - mean_absolute_error: 0.2270 - mean_squared_error: 0.0976 - acc: 0.4397 - pearson_correlation_f: 0.54022018-12-10 10:36:10.289749: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
47680/47680 [==============================] - 19s 408us/step - loss: 0.0968 - mean_absolute_error: 0.2257 - mean_squared_error: 0.0968 - acc: 0.4403 - pearson_correlation_f: 0.5438 - val_loss: 0.0164 - val_mean_absolute_error: 0.0888 - val_mean_squared_error: 0.0164 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9272
Epoch 2/60
47680/47680 [==============================] - 5s 112us/step - loss: 0.0161 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0161 - acc: 0.4999 - pearson_correlation_f: 0.9352 - val_loss: 0.0153 - val_mean_absolute_error: 0.0846 - val_mean_squared_error: 0.0153 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9378
Epoch 3/60
47680/47680 [==============================] - 6s 117us/step - loss: 0.0130 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0130 - acc: 0.5000 - pearson_correlation_f: 0.9457 - val_loss: 0.0122 - val_mean_absolute_error: 0.0727 - val_mean_squared_error: 0.0122 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9434
Epoch 4/60
47680/47680 [==============================] - 6s 117us/step - loss: 0.0113 - mean_absolute_error: 0.0751 - mean_squared_error: 0.0113 - acc: 0.5000 - pearson_correlation_f: 0.9523 - val_loss: 0.0124 - val_mean_absolute_error: 0.0768 - val_mean_squared_error: 0.0124 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9441
Epoch 5/60
47680/47680 [==============================] - 6s 118us/step - loss: 0.0099 - mean_absolute_error: 0.0696 - mean_squared_error: 0.0099 - acc: 0.5000 - pearson_correlation_f: 0.9580 - val_loss: 0.0108 - val_mean_absolute_error: 0.0673 - val_mean_squared_error: 0.0108 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9464
Epoch 6/60
47680/47680 [==============================] - 6s 118us/step - loss: 0.0087 - mean_absolute_error: 0.0647 - mean_squared_error: 0.0087 - acc: 0.5000 - pearson_correlation_f: 0.9637 - val_loss: 0.0113 - val_mean_absolute_error: 0.0706 - val_mean_squared_error: 0.0113 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9446
Epoch 7/60
47680/47680 [==============================] - 6s 119us/step - loss: 0.0076 - mean_absolute_error: 0.0603 - mean_squared_error: 0.0076 - acc: 0.5000 - pearson_correlation_f: 0.9682 - val_loss: 0.0129 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0129 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9439
Epoch 8/60
47680/47680 [==============================] - 6s 118us/step - loss: 0.0067 - mean_absolute_error: 0.0560 - mean_squared_error: 0.0067 - acc: 0.5000 - pearson_correlation_f: 0.9720 - val_loss: 0.0163 - val_mean_absolute_error: 0.0935 - val_mean_squared_error: 0.0163 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9422
2018-12-10 10:36:50.649617: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
5960/5960 [==============================] - 1s 87us/step
Test result:  [0.016786157887353992, 0.09363818381656737, 0.016786157887353992, 0.5, 0.943687677063398]
python3 main.py mutate USE-Large CNN --extra=delete
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 CNN delete
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29801 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47682, 50, 512) (47682,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47682 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:38:47.728905: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:38:48.229766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:38:48.230563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:38:48.230583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:38:56.880257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:38:56.880297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:38:56.880307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:38:56.884585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 10:39:02.855526: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
47104/47682 [============================>.] - ETA: 0s - loss: 0.1004 - mean_absolute_error: 0.2548 - mean_squared_error: 0.1004 - acc: 0.4465 - pearson_correlation_f: 0.39352018-12-10 10:39:06.377735: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.13GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
47682/47682 [==============================] - 19s 401us/step - loss: 0.0996 - mean_absolute_error: 0.2536 - mean_squared_error: 0.0996 - acc: 0.4474 - pearson_correlation_f: 0.3985 - val_loss: 0.0389 - val_mean_absolute_error: 0.1448 - val_mean_squared_error: 0.0389 - val_acc: 0.4987 - val_pearson_correlation_f: 0.8269
Epoch 2/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0300 - mean_absolute_error: 0.1320 - mean_squared_error: 0.0300 - acc: 0.4973 - pearson_correlation_f: 0.8658 - val_loss: 0.0274 - val_mean_absolute_error: 0.1276 - val_mean_squared_error: 0.0274 - val_acc: 0.4965 - val_pearson_correlation_f: 0.8732
Epoch 3/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0227 - mean_absolute_error: 0.1119 - mean_squared_error: 0.0227 - acc: 0.4982 - pearson_correlation_f: 0.8963 - val_loss: 0.0239 - val_mean_absolute_error: 0.1069 - val_mean_squared_error: 0.0239 - val_acc: 0.4990 - val_pearson_correlation_f: 0.8927
Epoch 4/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0193 - mean_absolute_error: 0.1012 - mean_squared_error: 0.0193 - acc: 0.4984 - pearson_correlation_f: 0.9116 - val_loss: 0.0200 - val_mean_absolute_error: 0.1003 - val_mean_squared_error: 0.0200 - val_acc: 0.4985 - val_pearson_correlation_f: 0.8990
Epoch 5/60
47682/47682 [==============================] - 4s 85us/step - loss: 0.0169 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0169 - acc: 0.4988 - pearson_correlation_f: 0.9220 - val_loss: 0.0191 - val_mean_absolute_error: 0.0928 - val_mean_squared_error: 0.0191 - val_acc: 0.4985 - val_pearson_correlation_f: 0.9062
Epoch 6/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0153 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0153 - acc: 0.4993 - pearson_correlation_f: 0.9306 - val_loss: 0.0204 - val_mean_absolute_error: 0.0941 - val_mean_squared_error: 0.0204 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9072
Epoch 7/60
47682/47682 [==============================] - 4s 85us/step - loss: 0.0137 - mean_absolute_error: 0.0829 - mean_squared_error: 0.0137 - acc: 0.4992 - pearson_correlation_f: 0.9370 - val_loss: 0.0197 - val_mean_absolute_error: 0.1020 - val_mean_squared_error: 0.0197 - val_acc: 0.4971 - val_pearson_correlation_f: 0.9064
Epoch 8/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0126 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0126 - acc: 0.4994 - pearson_correlation_f: 0.9435 - val_loss: 0.0189 - val_mean_absolute_error: 0.0982 - val_mean_squared_error: 0.0189 - val_acc: 0.4982 - val_pearson_correlation_f: 0.9054
Epoch 9/60
47682/47682 [==============================] - 4s 85us/step - loss: 0.0115 - mean_absolute_error: 0.0756 - mean_squared_error: 0.0115 - acc: 0.4995 - pearson_correlation_f: 0.9484 - val_loss: 0.0185 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.0185 - val_acc: 0.4982 - val_pearson_correlation_f: 0.9069
Epoch 10/60
47682/47682 [==============================] - 4s 85us/step - loss: 0.0106 - mean_absolute_error: 0.0725 - mean_squared_error: 0.0106 - acc: 0.4996 - pearson_correlation_f: 0.9529 - val_loss: 0.0184 - val_mean_absolute_error: 0.0878 - val_mean_squared_error: 0.0184 - val_acc: 0.4978 - val_pearson_correlation_f: 0.9086
Epoch 11/60
47682/47682 [==============================] - 4s 85us/step - loss: 0.0099 - mean_absolute_error: 0.0700 - mean_squared_error: 0.0099 - acc: 0.4997 - pearson_correlation_f: 0.9564 - val_loss: 0.0194 - val_mean_absolute_error: 0.0882 - val_mean_squared_error: 0.0194 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9070
Epoch 12/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0092 - mean_absolute_error: 0.0673 - mean_squared_error: 0.0092 - acc: 0.4998 - pearson_correlation_f: 0.9601 - val_loss: 0.0220 - val_mean_absolute_error: 0.1078 - val_mean_squared_error: 0.0220 - val_acc: 0.4953 - val_pearson_correlation_f: 0.9017
Epoch 13/60
47682/47682 [==============================] - 4s 84us/step - loss: 0.0087 - mean_absolute_error: 0.0655 - mean_squared_error: 0.0087 - acc: 0.4999 - pearson_correlation_f: 0.9626 - val_loss: 0.0193 - val_mean_absolute_error: 0.0876 - val_mean_squared_error: 0.0193 - val_acc: 0.4971 - val_pearson_correlation_f: 0.9061
2018-12-10 10:39:55.973806: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
5960/5960 [==============================] - 0s 76us/step
Test result:  [0.019696111754583034, 0.08827862311529633, 0.019696111754583034, 0.4956375838926175, 0.9020564005678933]
python3 main.py mutate USE-Large CNN --extra=replace
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 CNN replace
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29804 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47688, 50, 512) (47688,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 46, 128)           327808    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 344,449
Trainable params: 344,449
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47688 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:41:51.012865: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:41:51.596724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:41:51.597465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:41:51.597484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:42:00.500847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:42:00.500885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:42:00.500893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:42:00.506187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
2018-12-10 10:42:07.038653: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
47688/47688 [==============================] - 20s 419us/step - loss: 0.0901 - mean_absolute_error: 0.2120 - mean_squared_error: 0.0901 - acc: 0.4430 - pearson_correlation_f: 0.5919 - val_loss: 0.0228 - val_mean_absolute_error: 0.1175 - val_mean_squared_error: 0.0228 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9419
Epoch 2/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0119 - mean_absolute_error: 0.0804 - mean_squared_error: 0.0119 - acc: 0.5000 - pearson_correlation_f: 0.9546 - val_loss: 0.0112 - val_mean_absolute_error: 0.0737 - val_mean_squared_error: 0.0112 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9544
Epoch 3/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0093 - mean_absolute_error: 0.0693 - mean_squared_error: 0.0093 - acc: 0.5000 - pearson_correlation_f: 0.9626 - val_loss: 0.0087 - val_mean_absolute_error: 0.0671 - val_mean_squared_error: 0.0087 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9595
Epoch 4/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0078 - mean_absolute_error: 0.0621 - mean_squared_error: 0.0078 - acc: 0.5000 - pearson_correlation_f: 0.9675 - val_loss: 0.0083 - val_mean_absolute_error: 0.0627 - val_mean_squared_error: 0.0083 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9611
Epoch 5/60
47688/47688 [==============================] - 4s 83us/step - loss: 0.0068 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0068 - acc: 0.5000 - pearson_correlation_f: 0.9713 - val_loss: 0.0091 - val_mean_absolute_error: 0.0660 - val_mean_squared_error: 0.0091 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9618
Epoch 6/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0060 - mean_absolute_error: 0.0534 - mean_squared_error: 0.0060 - acc: 0.5000 - pearson_correlation_f: 0.9746 - val_loss: 0.0091 - val_mean_absolute_error: 0.0609 - val_mean_squared_error: 0.0091 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9614
Epoch 7/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0054 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0054 - acc: 0.5000 - pearson_correlation_f: 0.9778 - val_loss: 0.0079 - val_mean_absolute_error: 0.0572 - val_mean_squared_error: 0.0079 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9623
Epoch 8/60
47688/47688 [==============================] - 4s 83us/step - loss: 0.0048 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0048 - acc: 0.5000 - pearson_correlation_f: 0.9804 - val_loss: 0.0078 - val_mean_absolute_error: 0.0547 - val_mean_squared_error: 0.0078 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9619
Epoch 9/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0043 - mean_absolute_error: 0.0444 - mean_squared_error: 0.0043 - acc: 0.5000 - pearson_correlation_f: 0.9825 - val_loss: 0.0086 - val_mean_absolute_error: 0.0601 - val_mean_squared_error: 0.0086 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9611
Epoch 10/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0039 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0039 - acc: 0.5000 - pearson_correlation_f: 0.9843 - val_loss: 0.0080 - val_mean_absolute_error: 0.0599 - val_mean_squared_error: 0.0080 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9611
Epoch 11/60
47688/47688 [==============================] - 4s 84us/step - loss: 0.0035 - mean_absolute_error: 0.0405 - mean_squared_error: 0.0035 - acc: 0.5000 - pearson_correlation_f: 0.9862 - val_loss: 0.0089 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0089 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9597
2018-12-10 10:42:51.708330: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
5960/5960 [==============================] - 0s 76us/step
Test result:  [0.0089630336394446, 0.06305741465731755, 0.0089630336394446, 0.5, 0.9615403381770089]
python3 main.py mutate USE-Large LSTM --extra=add
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 LSTM add
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29802 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47684, 50, 512) (47684,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47684 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:44:41.934824: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:44:42.404549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:44:42.405397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:44:42.405423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:44:50.926758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:44:50.926805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:44:50.926813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:44:50.927804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47684/47684 [==============================] - 38s 792us/step - loss: 0.1243 - mean_absolute_error: 0.2546 - mean_squared_error: 0.1243 - acc: 0.4085 - pearson_correlation_f: 0.5723 - val_loss: 0.0223 - val_mean_absolute_error: 0.1081 - val_mean_squared_error: 0.0223 - val_acc: 0.5000 - val_pearson_correlation_f: 0.8995
Epoch 2/60
47684/47684 [==============================] - 23s 492us/step - loss: 0.0172 - mean_absolute_error: 0.0962 - mean_squared_error: 0.0172 - acc: 0.5000 - pearson_correlation_f: 0.9182 - val_loss: 0.0143 - val_mean_absolute_error: 0.0871 - val_mean_squared_error: 0.0143 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9276
Epoch 3/60
47684/47684 [==============================] - 23s 493us/step - loss: 0.0140 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0140 - acc: 0.5000 - pearson_correlation_f: 0.9341 - val_loss: 0.0125 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0125 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9367
Epoch 4/60
47684/47684 [==============================] - 23s 492us/step - loss: 0.0126 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0126 - acc: 0.5000 - pearson_correlation_f: 0.9405 - val_loss: 0.0145 - val_mean_absolute_error: 0.0854 - val_mean_squared_error: 0.0145 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9401
Epoch 5/60
47684/47684 [==============================] - 24s 493us/step - loss: 0.0118 - mean_absolute_error: 0.0765 - mean_squared_error: 0.0118 - acc: 0.5000 - pearson_correlation_f: 0.9442 - val_loss: 0.0122 - val_mean_absolute_error: 0.0812 - val_mean_squared_error: 0.0122 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9434
Epoch 6/60
47684/47684 [==============================] - 24s 497us/step - loss: 0.0112 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0112 - acc: 0.5000 - pearson_correlation_f: 0.9472 - val_loss: 0.0124 - val_mean_absolute_error: 0.0825 - val_mean_squared_error: 0.0124 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9466
Epoch 7/60
47684/47684 [==============================] - 23s 489us/step - loss: 0.0108 - mean_absolute_error: 0.0722 - mean_squared_error: 0.0108 - acc: 0.5000 - pearson_correlation_f: 0.9490 - val_loss: 0.0104 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0104 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9482
Epoch 8/60
47684/47684 [==============================] - 23s 492us/step - loss: 0.0104 - mean_absolute_error: 0.0706 - mean_squared_error: 0.0104 - acc: 0.5000 - pearson_correlation_f: 0.9506 - val_loss: 0.0115 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0115 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9486
Epoch 9/60
47684/47684 [==============================] - 24s 495us/step - loss: 0.0102 - mean_absolute_error: 0.0691 - mean_squared_error: 0.0102 - acc: 0.5000 - pearson_correlation_f: 0.9519 - val_loss: 0.0118 - val_mean_absolute_error: 0.0711 - val_mean_squared_error: 0.0118 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9488
Epoch 10/60
47684/47684 [==============================] - 23s 491us/step - loss: 0.0099 - mean_absolute_error: 0.0681 - mean_squared_error: 0.0099 - acc: 0.5000 - pearson_correlation_f: 0.9529 - val_loss: 0.0098 - val_mean_absolute_error: 0.0677 - val_mean_squared_error: 0.0098 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9513
Epoch 11/60
47684/47684 [==============================] - 24s 494us/step - loss: 0.0098 - mean_absolute_error: 0.0670 - mean_squared_error: 0.0098 - acc: 0.5000 - pearson_correlation_f: 0.9538 - val_loss: 0.0100 - val_mean_absolute_error: 0.0685 - val_mean_squared_error: 0.0100 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9516
Epoch 12/60
47684/47684 [==============================] - 24s 493us/step - loss: 0.0096 - mean_absolute_error: 0.0664 - mean_squared_error: 0.0096 - acc: 0.5000 - pearson_correlation_f: 0.9545 - val_loss: 0.0096 - val_mean_absolute_error: 0.0657 - val_mean_squared_error: 0.0096 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9525
Epoch 13/60
47684/47684 [==============================] - 24s 494us/step - loss: 0.0095 - mean_absolute_error: 0.0657 - mean_squared_error: 0.0095 - acc: 0.5000 - pearson_correlation_f: 0.9550 - val_loss: 0.0098 - val_mean_absolute_error: 0.0676 - val_mean_squared_error: 0.0098 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9520
Epoch 14/60
47684/47684 [==============================] - 23s 491us/step - loss: 0.0093 - mean_absolute_error: 0.0649 - mean_squared_error: 0.0093 - acc: 0.5000 - pearson_correlation_f: 0.9555 - val_loss: 0.0099 - val_mean_absolute_error: 0.0686 - val_mean_squared_error: 0.0099 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9526
Epoch 15/60
47684/47684 [==============================] - 24s 498us/step - loss: 0.0092 - mean_absolute_error: 0.0644 - mean_squared_error: 0.0092 - acc: 0.5000 - pearson_correlation_f: 0.9562 - val_loss: 0.0099 - val_mean_absolute_error: 0.0702 - val_mean_squared_error: 0.0099 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9534
5960/5960 [==============================] - 4s 640us/step
Test result:  [0.010080435714565667, 0.07087384500359528, 0.010080435714565667, 0.5, 0.9552831140140559]
python3 main.py mutate USE-Large LSTM --extra=delete
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 LSTM delete
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29801 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47682, 50, 512) (47682,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47682 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 10:52:39.894447: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 10:52:40.354175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 10:52:40.354710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 10:52:40.354731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 10:52:48.944238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:52:48.944276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 10:52:48.944285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 10:52:48.946333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47682/47682 [==============================] - 38s 795us/step - loss: 0.1482 - mean_absolute_error: 0.3025 - mean_squared_error: 0.1482 - acc: 0.3969 - pearson_correlation_f: 0.4712 - val_loss: 0.0430 - val_mean_absolute_error: 0.1693 - val_mean_squared_error: 0.0430 - val_acc: 0.4953 - val_pearson_correlation_f: 0.7720
Epoch 2/60
47682/47682 [==============================] - 24s 498us/step - loss: 0.0321 - mean_absolute_error: 0.1422 - mean_squared_error: 0.0321 - acc: 0.4958 - pearson_correlation_f: 0.8351 - val_loss: 0.0251 - val_mean_absolute_error: 0.1246 - val_mean_squared_error: 0.0251 - val_acc: 0.4968 - val_pearson_correlation_f: 0.8722
Epoch 3/60
47682/47682 [==============================] - 24s 496us/step - loss: 0.0241 - mean_absolute_error: 0.1205 - mean_squared_error: 0.0241 - acc: 0.4962 - pearson_correlation_f: 0.8805 - val_loss: 0.0219 - val_mean_absolute_error: 0.1158 - val_mean_squared_error: 0.0219 - val_acc: 0.4977 - val_pearson_correlation_f: 0.8910
Epoch 4/60
47682/47682 [==============================] - 24s 497us/step - loss: 0.0214 - mean_absolute_error: 0.1127 - mean_squared_error: 0.0214 - acc: 0.4971 - pearson_correlation_f: 0.8943 - val_loss: 0.0197 - val_mean_absolute_error: 0.1086 - val_mean_squared_error: 0.0197 - val_acc: 0.4977 - val_pearson_correlation_f: 0.9013
Epoch 5/60
47682/47682 [==============================] - 24s 499us/step - loss: 0.0199 - mean_absolute_error: 0.1078 - mean_squared_error: 0.0199 - acc: 0.4973 - pearson_correlation_f: 0.9022 - val_loss: 0.0194 - val_mean_absolute_error: 0.1071 - val_mean_squared_error: 0.0194 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9070
Epoch 6/60
47682/47682 [==============================] - 24s 497us/step - loss: 0.0190 - mean_absolute_error: 0.1047 - mean_squared_error: 0.0190 - acc: 0.4977 - pearson_correlation_f: 0.9072 - val_loss: 0.0200 - val_mean_absolute_error: 0.1073 - val_mean_squared_error: 0.0200 - val_acc: 0.4990 - val_pearson_correlation_f: 0.9097
Epoch 7/60
47682/47682 [==============================] - 24s 494us/step - loss: 0.0180 - mean_absolute_error: 0.1015 - mean_squared_error: 0.0180 - acc: 0.4979 - pearson_correlation_f: 0.9117 - val_loss: 0.0192 - val_mean_absolute_error: 0.1072 - val_mean_squared_error: 0.0192 - val_acc: 0.4978 - val_pearson_correlation_f: 0.9125
Epoch 8/60
47682/47682 [==============================] - 24s 498us/step - loss: 0.0173 - mean_absolute_error: 0.0992 - mean_squared_error: 0.0173 - acc: 0.4982 - pearson_correlation_f: 0.9151 - val_loss: 0.0170 - val_mean_absolute_error: 0.0991 - val_mean_squared_error: 0.0170 - val_acc: 0.4982 - val_pearson_correlation_f: 0.9152
Epoch 9/60
47682/47682 [==============================] - 24s 497us/step - loss: 0.0165 - mean_absolute_error: 0.0962 - mean_squared_error: 0.0165 - acc: 0.4982 - pearson_correlation_f: 0.9194 - val_loss: 0.0160 - val_mean_absolute_error: 0.0946 - val_mean_squared_error: 0.0160 - val_acc: 0.4985 - val_pearson_correlation_f: 0.9206
Epoch 10/60
47682/47682 [==============================] - 24s 496us/step - loss: 0.0157 - mean_absolute_error: 0.0930 - mean_squared_error: 0.0157 - acc: 0.4982 - pearson_correlation_f: 0.9230 - val_loss: 0.0153 - val_mean_absolute_error: 0.0924 - val_mean_squared_error: 0.0153 - val_acc: 0.4980 - val_pearson_correlation_f: 0.9246
Epoch 11/60
47682/47682 [==============================] - 24s 499us/step - loss: 0.0150 - mean_absolute_error: 0.0898 - mean_squared_error: 0.0150 - acc: 0.4983 - pearson_correlation_f: 0.9266 - val_loss: 0.0158 - val_mean_absolute_error: 0.0911 - val_mean_squared_error: 0.0158 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9229
Epoch 12/60
47682/47682 [==============================] - 24s 495us/step - loss: 0.0144 - mean_absolute_error: 0.0871 - mean_squared_error: 0.0144 - acc: 0.4984 - pearson_correlation_f: 0.9297 - val_loss: 0.0144 - val_mean_absolute_error: 0.0866 - val_mean_squared_error: 0.0144 - val_acc: 0.4987 - val_pearson_correlation_f: 0.9288
Epoch 13/60
47682/47682 [==============================] - 24s 499us/step - loss: 0.0139 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0139 - acc: 0.4984 - pearson_correlation_f: 0.9321 - val_loss: 0.0157 - val_mean_absolute_error: 0.0883 - val_mean_squared_error: 0.0157 - val_acc: 0.4988 - val_pearson_correlation_f: 0.9307
Epoch 14/60
47682/47682 [==============================] - 24s 497us/step - loss: 0.0135 - mean_absolute_error: 0.0824 - mean_squared_error: 0.0135 - acc: 0.4985 - pearson_correlation_f: 0.9343 - val_loss: 0.0164 - val_mean_absolute_error: 0.0945 - val_mean_squared_error: 0.0164 - val_acc: 0.4973 - val_pearson_correlation_f: 0.9291
Epoch 15/60
47682/47682 [==============================] - 24s 495us/step - loss: 0.0131 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0131 - acc: 0.4987 - pearson_correlation_f: 0.9361 - val_loss: 0.0133 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0133 - val_acc: 0.4982 - val_pearson_correlation_f: 0.9342
Epoch 16/60
47682/47682 [==============================] - 24s 498us/step - loss: 0.0128 - mean_absolute_error: 0.0796 - mean_squared_error: 0.0128 - acc: 0.4985 - pearson_correlation_f: 0.9376 - val_loss: 0.0133 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0133 - val_acc: 0.4985 - val_pearson_correlation_f: 0.9346
Epoch 17/60
47682/47682 [==============================] - 24s 496us/step - loss: 0.0125 - mean_absolute_error: 0.0782 - mean_squared_error: 0.0125 - acc: 0.4988 - pearson_correlation_f: 0.9391 - val_loss: 0.0134 - val_mean_absolute_error: 0.0798 - val_mean_squared_error: 0.0134 - val_acc: 0.4983 - val_pearson_correlation_f: 0.9349
Epoch 18/60
47682/47682 [==============================] - 24s 499us/step - loss: 0.0122 - mean_absolute_error: 0.0772 - mean_squared_error: 0.0122 - acc: 0.4988 - pearson_correlation_f: 0.9402 - val_loss: 0.0133 - val_mean_absolute_error: 0.0799 - val_mean_squared_error: 0.0133 - val_acc: 0.4977 - val_pearson_correlation_f: 0.9346
Epoch 19/60
47682/47682 [==============================] - 24s 496us/step - loss: 0.0120 - mean_absolute_error: 0.0763 - mean_squared_error: 0.0120 - acc: 0.4987 - pearson_correlation_f: 0.9415 - val_loss: 0.0136 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0136 - val_acc: 0.4971 - val_pearson_correlation_f: 0.9340
5960/5960 [==============================] - 4s 637us/step
Test result:  [0.013860472240766523, 0.08014664178926673, 0.013860472240766523, 0.49731543624161073, 0.9298515244618358]
python3 main.py mutate USE-Large LSTM --extra=replace
Using TensorFlow backend.
Setting:  mutate USE-Large 30000 1 LSTM replace
loading data ..
loading pickle ..
retrieving article ..
Warning: removed invalid samples. Valid: 29801 all: 30000
merging data ..
padding ..
padding articles ..
padding summaries ..
concatenating ..
splitting by group ..
shuffling ..
splitting ..
train:  (47682, 50, 512) (47682,)
val:  (5960, 50, 512) (5960,)
test:  (5960, 50, 512) (5960,)
building model ..
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 50, 512)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 25)                53800     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 26        
=================================================================
Total params: 53,826
Trainable params: 53,826
Non-trainable params: 0
_________________________________________________________________
training ..
Train on 47682 samples, validate on 5960 samples
Epoch 1/60
2018-12-10 11:02:13.939895: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-10 11:02:14.416586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-10 11:02:14.417134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:0b:00.0
totalMemory: 2.95GiB freeMemory: 2.75GiB
2018-12-10 11:02:14.417153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-10 11:02:22.806601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 11:02:22.806640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-10 11:02:22.806649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-10 11:02:22.807638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2456 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:0b:00.0, compute capability: 6.1)
47682/47682 [==============================] - 38s 791us/step - loss: 0.1169 - mean_absolute_error: 0.2391 - mean_squared_error: 0.1169 - acc: 0.4067 - pearson_correlation_f: 0.6267 - val_loss: 0.0152 - val_mean_absolute_error: 0.0878 - val_mean_squared_error: 0.0152 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9280
Epoch 2/60
47682/47682 [==============================] - 25s 529us/step - loss: 0.0129 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0129 - acc: 0.4999 - pearson_correlation_f: 0.9401 - val_loss: 0.0105 - val_mean_absolute_error: 0.0739 - val_mean_squared_error: 0.0105 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9497
Epoch 3/60
47682/47682 [==============================] - 25s 528us/step - loss: 0.0103 - mean_absolute_error: 0.0732 - mean_squared_error: 0.0103 - acc: 0.5000 - pearson_correlation_f: 0.9527 - val_loss: 0.0091 - val_mean_absolute_error: 0.0690 - val_mean_squared_error: 0.0091 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9575
Epoch 4/60
47682/47682 [==============================] - 25s 526us/step - loss: 0.0091 - mean_absolute_error: 0.0684 - mean_squared_error: 0.0091 - acc: 0.5000 - pearson_correlation_f: 0.9582 - val_loss: 0.0101 - val_mean_absolute_error: 0.0739 - val_mean_squared_error: 0.0101 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9618
Epoch 5/60
47682/47682 [==============================] - 25s 527us/step - loss: 0.0084 - mean_absolute_error: 0.0653 - mean_squared_error: 0.0084 - acc: 0.5000 - pearson_correlation_f: 0.9611 - val_loss: 0.0077 - val_mean_absolute_error: 0.0631 - val_mean_squared_error: 0.0077 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9637
Epoch 6/60
47682/47682 [==============================] - 25s 527us/step - loss: 0.0080 - mean_absolute_error: 0.0635 - mean_squared_error: 0.0080 - acc: 0.5000 - pearson_correlation_f: 0.9629 - val_loss: 0.0075 - val_mean_absolute_error: 0.0623 - val_mean_squared_error: 0.0075 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9653
Epoch 7/60
47682/47682 [==============================] - 25s 528us/step - loss: 0.0077 - mean_absolute_error: 0.0620 - mean_squared_error: 0.0077 - acc: 0.5000 - pearson_correlation_f: 0.9645 - val_loss: 0.0077 - val_mean_absolute_error: 0.0613 - val_mean_squared_error: 0.0077 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9666
Epoch 8/60
47682/47682 [==============================] - 25s 527us/step - loss: 0.0074 - mean_absolute_error: 0.0606 - mean_squared_error: 0.0074 - acc: 0.5000 - pearson_correlation_f: 0.9656 - val_loss: 0.0076 - val_mean_absolute_error: 0.0622 - val_mean_squared_error: 0.0076 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9670
Epoch 9/60
47682/47682 [==============================] - 25s 526us/step - loss: 0.0072 - mean_absolute_error: 0.0595 - mean_squared_error: 0.0072 - acc: 0.5000 - pearson_correlation_f: 0.9667 - val_loss: 0.0068 - val_mean_absolute_error: 0.0581 - val_mean_squared_error: 0.0068 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9681
Epoch 10/60
47682/47682 [==============================] - 25s 527us/step - loss: 0.0070 - mean_absolute_error: 0.0584 - mean_squared_error: 0.0070 - acc: 0.5000 - pearson_correlation_f: 0.9676 - val_loss: 0.0066 - val_mean_absolute_error: 0.0573 - val_mean_squared_error: 0.0066 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9687
Epoch 11/60
47682/47682 [==============================] - 25s 528us/step - loss: 0.0069 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0069 - acc: 0.5000 - pearson_correlation_f: 0.9682 - val_loss: 0.0067 - val_mean_absolute_error: 0.0576 - val_mean_squared_error: 0.0067 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9692
Epoch 12/60
47682/47682 [==============================] - 25s 530us/step - loss: 0.0067 - mean_absolute_error: 0.0568 - mean_squared_error: 0.0067 - acc: 0.5000 - pearson_correlation_f: 0.9689 - val_loss: 0.0071 - val_mean_absolute_error: 0.0626 - val_mean_squared_error: 0.0071 - val_acc: 0.5000 - val_pearson_correlation_f: 0.9698
Epoch 13/60
47682/47682 [==============================] - 25s 526us/step - loss: 0.0066 - mean_absolute_error: 0.0561 - mean_squared_error: 0.0066 - acc: 0.5000 - pearson_correlation_f: 0.9694 - val_loss: 0.0075 - val_mean_absolute_error: 0.0608 - val_mean_squared_error: 0.0075 - val_acc: 0.4998 - val_pearson_correlation_f: 0.9695
5960/5960 [==============================] - 4s 627us/step
Test result:  [0.007782359650021032, 0.061763567302451035, 0.007782359650021032, 0.5, 0.9694835553233255]
